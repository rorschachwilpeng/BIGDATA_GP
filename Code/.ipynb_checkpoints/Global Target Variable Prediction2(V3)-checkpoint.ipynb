{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"Global\") \n",
    "sc = SparkContext(conf = conf)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Global Models\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier,OneVsRest\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.regression import FMRegressor\n",
    "from pyspark.ml.classification import RandomForestClassificationModel\n",
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark = SparkSession.builder.master(\"global\").appName(\"GlobalModels\").getOrCreate()\n",
    "\n",
    "# Load original dataset\n",
    "# df = spark.read.options(delimiter=\",\",inferSchema=True,header=False).csv(\"../Data/Processed Data/\")\n",
    "\n",
    "# Load smaller dataset\n",
    "df = spark.read.options(delimiter=\",\",inferSchema=True,header=False).csv(\"../Data/Smaller Dataset.csv\")\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "df = df.withColumn(\"time\", df[\"_c0\"].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Discretization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform continous data, \"vehicle speed\", \"engine load\", \"engine RPM\", \"Pitch\" into discretized type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vehicle speed -> _c17\n",
    "engine load -> _c18\n",
    "engine RPM -> _c19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### http://ijj.acm.org/volumes/volume2/no4/ijjvol2no4p6.pdf -> Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vehicle Speed\n",
    "VS_discretizer = QuantileDiscretizer(numBuckets=10, inputCol=\"_c1\", outputCol=\"_c17\")\n",
    "\n",
    "### Engine Load\n",
    "EL_discretizer = QuantileDiscretizer(numBuckets=10, inputCol=\"_c3\", outputCol=\"_c18\")\n",
    "\n",
    "### Engine RPM\n",
    "RPM_discretizer = QuantileDiscretizer(numBuckets=10, inputCol=\"_c5\", outputCol=\"_c19\")\n",
    "\n",
    "data3 = VS_discretizer.fit(df).transform(df)\n",
    "data2 = EL_discretizer.fit(data3).transform(data3)\n",
    "data = RPM_discretizer.fit(data2).transform(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Transform into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Target 1 - Vehicle Speed Training & Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some attributes are deleted base on correlation analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Aceeleration,Lateral Acceleration,Pitch is delted, \n",
    "### Vehicle Speed Dataset\n",
    "# feature selection\n",
    "vehicleSpeed_va = VectorAssembler(inputCols=[\"time\",\"_c2\",\"_c8\",\"_c10\",\"_c11\",\"_c12\",\"_c14\",\"_c17\",\"_c18\",\"_c19\"], outputCol=\"features\")\n",
    "vehicleSpeed_adj = vehicleSpeed_va.setHandleInvalid(\"skip\").transform(data)\n",
    "\n",
    "\n",
    "# target variable selection(Vehicle Speed)\n",
    "vehicleSpeed_lab = vehicleSpeed_adj.select(\"time\",\"features\", \"_c17\")\n",
    "vehicleSpeed_data_selected = vehicleSpeed_lab.withColumnRenamed(\"_c17\", \"label\")\n",
    "\n",
    "# Split the data into multiple training and test sets\n",
    "(vehicleSpeed_trainingData1, vehicleSpeed_testData1, vehicleSpeed_trainingData2, vehicleSpeed_testData2,\n",
    " vehicleSpeed_trainingData3, vehicleSpeed_testData3, vehicleSpeed_trainingData4,vehicleSpeed_testData4) = vehicleSpeed_data_selected.randomSplit([0.15,0.1,0.15,0.1,0.15,0.1,0.15,0.1],seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Target 2 - Rain Intensity Training & Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Aceeleration,Lateral Acceleration,Pitch is delted\n",
    "### Rain Intensity Dataset\n",
    "# feature selection\n",
    "rainIntensity_va = VectorAssembler(inputCols=[\"time\",\"_c2\",\"_c8\",\"_c10\",\"_c11\",\"_c12\",\"_c13\",\"_c14\",\"_c18\",\"_c19\"], outputCol=\"features\")\n",
    "rainIntensity_adj = rainIntensity_va.setHandleInvalid(\"skip\").transform(data)\n",
    "\n",
    "# target variable selection(Rain Intensity)\n",
    "rainIntensity_lab = rainIntensity_adj.select(\"time\",\"features\", \"_c13\")\n",
    "rainIntensity_data_selected = rainIntensity_lab.withColumnRenamed(\"_c13\", \"label\")\n",
    "\n",
    "# Split the data into multiple training and test sets\n",
    "(rainIntensity_trainingData1, rainIntensity_testData1, rainIntensity_trainingData2, rainIntensity_testData2,\n",
    " rainIntensity_trainingData3, rainIntensity_testData3, rainIntensity_trainingData4, rainIntensity_testData4) = rainIntensity_data_selected.randomSplit([0.15,0.1,0.15,0.1,0.15,0.1,0.15,0.1],seed=2345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Target 3 - Driver's Wellbeing Training & Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Aceeleration,Lateral Acceleration,Pitch is delted\n",
    "### Driver's Wellbeing Dataset\n",
    "# feature selection\n",
    "driverWellbeing_va = VectorAssembler(inputCols=[\"time\",\"_c2\",\"_c8\",\"_c10\",\"_c11\",\"_c12\",\"_c14\",\"_c15\",\"_c18\",\"_c19\"], outputCol=\"features\")\n",
    "driverWellbeing_adj = driverWellbeing_va.setHandleInvalid(\"skip\").transform(data)\n",
    "\n",
    "# target variable selection(Driver Wellbeing)\n",
    "driverWellbeing_lab = driverWellbeing_adj.select(\"time\",\"features\", \"_c15\")\n",
    "driverWellbeing_data_selected = driverWellbeing_lab.withColumnRenamed(\"_c15\", \"label\")\n",
    "\n",
    "# Split the data into multiple training and test sets\n",
    "(driverWellbeing_trainingData1, driverWellbeing_testData1, driverWellbeing_trainingData2, driverWellbeing_testData2,\n",
    " driverWellbeing_trainingData3, driverWellbeing_testData3, driverWellbeing_trainingData4, driverWellbeing_testData4) = driverWellbeing_data_selected.randomSplit([0.15,0.1,0.15,0.1,0.15,0.1,0.15,0.1],seed=3456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Target 4 - Driver's Rush Training & Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Aceeleration,Lateral Acceleration,Pitch is delted\n",
    "### Driver's Rush Dataset\n",
    "# feature selection\n",
    "driverRush_va = VectorAssembler(inputCols=[\"time\",\"_c2\",\"_c8\",\"_c10\",\"_c11\",\"_c12\",\"_c14\",\"_c16\",\"_c18\",\"_c19\"], outputCol=\"features\")\n",
    "driverRush_adj = driverRush_va.setHandleInvalid(\"skip\").transform(data)\n",
    "\n",
    "# target variable selection(Driver Rush)\n",
    "driverRush_lab = driverRush_adj.select(\"time\",\"features\", \"_c16\")\n",
    "driverRush_data_selected = driverRush_lab.withColumnRenamed(\"_c16\", \"label\")\n",
    "\n",
    "# Split the data into multiple training and test sets\n",
    "(driverRush_trainingData1, driverRush_testData1, driverRush_trainingData2, driverRush_testData2,\n",
    " driverRush_trainingData3, driverRush_testData3, driverRush_trainingData4, driverRush_testData4,) = driverRush_data_selected.randomSplit([0.15,0.1,0.15,0.1,0.15,0.1,0.15,0.1],seed=4567)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Data Resampling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 SMOTE (Advanced Method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1(0) SMOTE Overall structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/image.py:167: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:35: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:597: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:836: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:862: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1097: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1344: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/least_angle.py:1480: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:152: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  precompute=False, eps=np.finfo(np.float).eps,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:320: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, random_state=None,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/randomized_l1.py:580: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=4 * np.finfo(np.float).eps, n_jobs=None,\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/online_lda.py:31: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n",
      "/Users/apple/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py:34: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  from ._gradient_boosting import predict_stages\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from numpy import zeros, newaxis\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "#######################\n",
    "##### Input: Dataset with different number of multiple label classes\n",
    "##### Output: Dataset with same number of multiple label classes\n",
    "#######################\n",
    "def SMOTE_PROCESS(training_dataset):\n",
    "    # Extract label and features\n",
    "    y = np.array(training_dataset.select('label').collect())\n",
    "    X = np.array(training_dataset.select('features').collect())\n",
    "    # Reshape array's size (SMOTE function only take 2d array)\n",
    "    new_X = X.reshape(X.shape[0],X.shape[2])\n",
    "    new_y = y.flatten()\n",
    "    # Driver Wellbeing\n",
    "    X_resampled, y_resampled = SMOTE(sampling_strategy={2: 25000}).fit_resample(new_X, new_y)\n",
    "    \n",
    "    # print(sorted(Counter(y_resampled).items()))\n",
    "    \n",
    "    ## Transform dataframe into spark dataframe\n",
    "    xResample = X_resampled[:, newaxis,:]\n",
    "    yResample = y_resampled[:,newaxis]\n",
    "    xResample = xResample.astype(int)\n",
    "    yResample = yResample.astype(int)\n",
    "    ## Rebuild feature \n",
    "    featureSchema = StructType([\n",
    "      StructField(\"features\", ArrayType(IntegerType()), True),\n",
    "    ])\n",
    "\n",
    "    df_feature = spark.createDataFrame(xResample.tolist(),schema=featureSchema)\n",
    "    ## Rebulid label\n",
    "    labelSchema = StructType([\n",
    "      StructField(\"label\", IntegerType(), True),\n",
    "    ])\n",
    "    \n",
    "    df_label = spark.createDataFrame(yResample.tolist(),schema=labelSchema)\n",
    "    ## Combine two dataframe with a outter key\n",
    "    df1 = df_feature.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df2 = df_label.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df_data = df2.join(df1, \"id\", \"outer\").drop(\"id\")\n",
    "    df_data.show()\n",
    "    ### Transform the feature type into vector(which can be regnonized by the training model)\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    df_data = df_data.select( \n",
    "    df_data[\"label\"],\n",
    "    list_to_vector_udf(df_data[\"features\"]).alias(\"features\")\n",
    "    )\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1(1)  T1- Vehicle Speed Resampling based on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A. Vehicle Speed Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 1177|\n",
      "|  1.0| 1203|\n",
      "|  2.0| 1218|\n",
      "|  3.0| 1191|\n",
      "|  4.0| 1149|\n",
      "|  5.0| 1215|\n",
      "|  6.0| 1168|\n",
      "|  7.0| 1160|\n",
      "|  8.0| 1158|\n",
      "|  9.0| 1206|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original dataset label class distribution\n",
    "vehicleSpeed_trainingData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[58.097,0.0,0.0,0...|  0.0|\n",
      "|[60.307,0.0,0.0,0...|  0.0|\n",
      "|[68.347,0.0,0.0,0...|  0.0|\n",
      "|[69.387,0.0,0.0,0...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[163.65,0.0,0.0,0...|  0.0|\n",
      "|[194.28,0.0,0.0,0...|  0.0|\n",
      "|(10,[0,5,6,9],[22...|  0.0|\n",
      "|(10,[0,4,5,6,8],[...|  0.0|\n",
      "|[261.48,0.0,4.0,1...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,5,6,8],[...|  0.0|\n",
      "|(10,[0,4,5,6,8],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,5,6],[34...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[357.23,0.0,0.0,1...|  0.0|\n",
      "|[430.93,0.0,0.0,0...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  186|\n",
      "|  1.0|  172|\n",
      "|  2.0|  172|\n",
      "|  3.0|  169|\n",
      "|  4.0|  169|\n",
      "|  5.0|  176|\n",
      "|  6.0|  168|\n",
      "|  7.0|  188|\n",
      "|  8.0|  195|\n",
      "|  9.0|  179|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### VehicleSpeed Training Data\n",
    "### Resample the dataset\n",
    "from pyspark.sql.functions import col\n",
    "df_class_0 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "df_class_6 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 6).select(col(\"features\"),col(\"label\"))\n",
    "df_class_7 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 7).select(col(\"features\"),col(\"label\"))\n",
    "df_class_8 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 8).select(col(\"features\"),col(\"label\"))\n",
    "df_class_9 = vehicleSpeed_trainingData1.where(vehicleSpeed_trainingData1.label == 9).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# Sample 20% of dataset as training data --> 23386 each class\n",
    "df_class_0_over = df_class_0.sample(fraction=0.15,seed=123)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.15,seed=234)\n",
    "df_class_2_over = df_class_2.sample(fraction=0.15,seed=456)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.15,seed=567)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.15,seed=678)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.15,seed=789)\n",
    "df_class_6_over = df_class_6.sample(fraction=0.15,seed=891)\n",
    "df_class_7_over = df_class_7.sample(fraction=0.15,seed=999)\n",
    "df_class_8_over = df_class_8.sample(fraction=0.15,seed=987)\n",
    "df_class_9_over = df_class_9.sample(fraction=0.15,seed=876)\n",
    "# # Combine\n",
    "df_train_over = df_class_0_over.union(df_class_1_over)\n",
    "df_train_over = df_train_over.union(df_class_2_over)\n",
    "df_train_over = df_train_over.union(df_class_3_over)\n",
    "df_train_over = df_train_over.union(df_class_4_over)\n",
    "df_train_over = df_train_over.union(df_class_5_over)\n",
    "df_train_over = df_train_over.union(df_class_6_over)\n",
    "df_train_over = df_train_over.union(df_class_7_over)\n",
    "df_train_over = df_train_over.union(df_class_8_over)\n",
    "df_train_vehicleSpeed = df_train_over.union(df_class_9_over)\n",
    "df_train_vehicleSpeed.show()\n",
    "# Dataset label class distribution after resampling\n",
    "df_train_vehicleSpeed.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### B. Vehicle Speed Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  789|\n",
      "|  1.0|  758|\n",
      "|  2.0|  760|\n",
      "|  3.0|  792|\n",
      "|  4.0|  792|\n",
      "|  5.0|  751|\n",
      "|  6.0|  724|\n",
      "|  7.0|  721|\n",
      "|  8.0|  738|\n",
      "|  9.0|  787|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original dataset label's classes distribution\n",
    "vehicleSpeed_testData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,5,6,9],[...|  0.0|\n",
      "|(10,[0,4,5,6],[51...|  0.0|\n",
      "|(10,[0,4,5,6,8],[...|  0.0|\n",
      "|(10,[0,5,6,8],[69...|  0.0|\n",
      "|(10,[0,4,5,6,8],[...|  0.0|\n",
      "|(10,[0,5,6,8],[98...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8],[12...|  0.0|\n",
      "|(10,[0,5,6,8],[12...|  0.0|\n",
      "|(10,[0,4,5,6],[15...|  0.0|\n",
      "|[1533.0,0.0,4.0,1...|  0.0|\n",
      "|[1709.0,0.0,0.0,0...|  0.0|\n",
      "|(10,[0,5,6,8],[17...|  0.0|\n",
      "|(10,[0,5,6,8],[17...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8],[23...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|   36|\n",
      "|  1.0|   41|\n",
      "|  2.0|   50|\n",
      "|  3.0|   51|\n",
      "|  4.0|   44|\n",
      "|  5.0|   55|\n",
      "|  6.0|   49|\n",
      "|  7.0|   47|\n",
      "|  8.0|   49|\n",
      "|  9.0|   50|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Vehicle Speed Testing Data\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_0 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "df_class_6 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 6).select(col(\"features\"),col(\"label\"))\n",
    "df_class_7 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 7).select(col(\"features\"),col(\"label\"))\n",
    "df_class_8 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 8).select(col(\"features\"),col(\"label\"))\n",
    "df_class_9 = vehicleSpeed_testData1.where(vehicleSpeed_testData1.label == 9).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# # Sample smaller dataset as training data --> 5000 each class\n",
    "df_class_0_over = df_class_0.sample(fraction=0.06435,seed=123)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.06435,seed=234)\n",
    "df_class_2_over = df_class_2.sample(fraction=0.06435,seed=456)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.06435,seed=567)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.06435,seed=678)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.06435,seed=789)\n",
    "df_class_6_over = df_class_6.sample(fraction=0.06435,seed=891)\n",
    "df_class_7_over = df_class_7.sample(fraction=0.06435,seed=999)\n",
    "df_class_8_over = df_class_8.sample(fraction=0.06435,seed=987)\n",
    "df_class_9_over = df_class_9.sample(fraction=0.06435,seed=876)\n",
    "\n",
    "# # # Combine\n",
    "df_test_over = df_class_0_over.union(df_class_1_over)\n",
    "df_test_over = df_test_over.union(df_class_2_over)\n",
    "df_test_over = df_test_over.union(df_class_3_over)\n",
    "df_test_over = df_test_over.union(df_class_4_over)\n",
    "df_test_over = df_test_over.union(df_class_5_over)\n",
    "df_test_over = df_test_over.union(df_class_6_over)\n",
    "df_test_over = df_test_over.union(df_class_7_over)\n",
    "df_test_over = df_test_over.union(df_class_8_over)\n",
    "df_test_vehicleSpeed = df_test_over.union(df_class_9_over)\n",
    "df_test_vehicleSpeed.show()\n",
    "# Dataset label class distribution after resampling\n",
    "df_test_vehicleSpeed.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2(2) T2 - Rain Intensity Resampling based on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A. Rain Intensity Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 9059|\n",
      "|  1.0| 1899|\n",
      "|  2.0|   85|\n",
      "|  3.0|  585|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Orignal dataset label's class distribution\n",
    "rainIntensity_trainingData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    0|[9, 0, 0, 0, 0, 2...|\n",
      "|    0|[11, 0, 0, 0, 4, ...|\n",
      "|    0|[189, 5, 1, 0, 0,...|\n",
      "|    0|[391, 0, 0, 0, 0,...|\n",
      "|    0|[701, 5, 1, 0, 0,...|\n",
      "|    0|[708, 1, 0, 0, 0,...|\n",
      "|    0|[755, 0, 0, 0, 2,...|\n",
      "|    0|[821, 0, 0, 0, 2,...|\n",
      "|    0|[860, 3, 0, 0, 0,...|\n",
      "|    3|[940, 2, 0, 1, 0,...|\n",
      "|    3|[959, 4, 0, 1, 0,...|\n",
      "|    0|[1041, 5, 1, 0, 0...|\n",
      "|    0|[1069, 5, 1, 0, 0...|\n",
      "|    0|[1080, 5, 1, 0, 0...|\n",
      "|    0|[1256, 0, 0, 0, 0...|\n",
      "|    1|[1353, 0, 0, 0, 0...|\n",
      "|    3|[1488, 4, 0, 1, 0...|\n",
      "|    3|[1583, 0, 0, 1, 0...|\n",
      "|    0|[1586, 5, 1, 0, 0...|\n",
      "|    0|[1639, 5, 1, 0, 0...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1101.0,3.0,0.0,1...|    0|\n",
      "|[184.0,4.0,2.0,0....|    0|\n",
      "|[1673.0,5.0,1.0,0...|    0|\n",
      "|[1894.0,2.0,0.0,0...|    0|\n",
      "|[474.0,5.0,1.0,0....|    0|\n",
      "|[2372.0,0.0,0.0,0...|    0|\n",
      "|[79.0,1.0,2.0,0.0...|    0|\n",
      "|[137.0,3.0,0.0,0....|    0|\n",
      "|[174.0,0.0,0.0,1....|    0|\n",
      "|[1644.0,0.0,0.0,0...|    0|\n",
      "|[31.0,0.0,0.0,0.0...|    0|\n",
      "|[1875.0,0.0,0.0,1...|    0|\n",
      "|[47.0,0.0,1.0,0.0...|    0|\n",
      "|[1235.0,0.0,0.0,0...|    0|\n",
      "|[1767.0,3.0,0.0,0...|    0|\n",
      "|[170.0,2.0,3.0,0....|    0|\n",
      "|[618.0,2.0,0.0,0....|    0|\n",
      "|[833.0,0.0,1.0,0....|    0|\n",
      "|[1394.0,2.0,0.0,0...|    0|\n",
      "|[1360.0,0.0,0.0,0...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0|  396|\n",
      "|    1|  407|\n",
      "|    2|  400|\n",
      "|    3|  402|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "##### Input: Dataset with different number of multiple label classes\n",
    "##### Output: Dataset with same number of multiple label classes\n",
    "#######################\n",
    "def rainIntensity_SMOTE_PROCESS(training_dataset):\n",
    "    # Extract label and features\n",
    "    y = np.array(training_dataset.select('label').collect())\n",
    "    X = np.array(training_dataset.select('features').collect())\n",
    "    # Reshape array's size (SMOTE function only take 2d array)\n",
    "    new_X = X.reshape(X.shape[0],X.shape[2])\n",
    "    new_y = y.flatten()\n",
    "    ### Set number of class going to reach for specific class\n",
    "    ##Original dataset upsampling target number\n",
    "    #X_resampled, y_resampled = SMOTE(ratio={2: 40000}).fit_sample(new_X, new_y)\n",
    "    ##Smaller dataset test upsampling target number  \n",
    "    X_resampled, y_resampled = SMOTE(sampling_strategy={2: 400}).fit_resample(new_X, new_y)\n",
    "    \n",
    "    ## Transform dataframe into spark dataframe\n",
    "    xResample = X_resampled[:, newaxis,:]\n",
    "    yResample = y_resampled[:,newaxis]\n",
    "    xResample = xResample.astype(int)\n",
    "    yResample = yResample.astype(int)\n",
    "    ## Rebuild feature \n",
    "    featureSchema = StructType([\n",
    "      StructField(\"features\", ArrayType(IntegerType()), True),\n",
    "    ])\n",
    "\n",
    "    df_feature = spark.createDataFrame(xResample.tolist(),schema=featureSchema)\n",
    "    ## Rebulid label\n",
    "    labelSchema = StructType([\n",
    "      StructField(\"label\", IntegerType(), True),\n",
    "    ])\n",
    "    \n",
    "    df_label = spark.createDataFrame(yResample.tolist(),schema=labelSchema)\n",
    "    ## Combine two dataframe with a outter key\n",
    "    df1 = df_feature.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df2 = df_label.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df_data = df2.join(df1, \"id\", \"outer\").drop(\"id\")\n",
    "    df_data.show()\n",
    "    ### Transform the feature type into vector(which can be regnonized by the training model)\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    df_data = df_data.select( \n",
    "    df_data[\"label\"],\n",
    "    list_to_vector_udf(df_data[\"features\"]).alias(\"features\")\n",
    "    )\n",
    "    return df_data\n",
    "### RainIntensity Training Data\n",
    "rainIntensity_DF = rainIntensity_SMOTE_PROCESS(rainIntensity_trainingData1)\n",
    "### Resample the dataset\n",
    "from pyspark.sql.functions import col\n",
    "df_class_0 = rainIntensity_DF.where(rainIntensity_DF.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = rainIntensity_DF.where(rainIntensity_DF.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = rainIntensity_DF.where(rainIntensity_DF.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = rainIntensity_DF.where(rainIntensity_DF.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "# Sample 5% of dataset as training data --> approximately 40000 each class\n",
    "df_class_0_over = df_class_0.sample(fraction=0.044,seed=123)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.211,seed=234)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.6968,seed=567)\n",
    "# # Combine\n",
    "df_train_over = df_class_0_over.union(df_class_1_over)\n",
    "df_train_over = df_train_over.union(df_class_2)\n",
    "df_train_rainIntensity = df_train_over.union(df_class_3_over)\n",
    "df_train_rainIntensity.show()\n",
    "# Dataset label class distribution after resampling\n",
    "df_train_rainIntensity.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### B. Rain Intensity Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 6136|\n",
      "|  1.0| 1276|\n",
      "|  2.0|   40|\n",
      "|  3.0|  402|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original dataset label's classes distribution\n",
    "rainIntensity_testData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|[9.349,0.0,1.0,0....|  0.0|\n",
      "|(10,[0,2,5,7],[10...|  0.0|\n",
      "|[17.815,0.0,1.0,0...|  0.0|\n",
      "|[30.727,2.0,0.0,0...|  0.0|\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|(10,[0,2,5,7,8],[...|  0.0|\n",
      "|[79.235,0.0,1.0,0...|  0.0|\n",
      "|[96.429,5.0,1.0,0...|  0.0|\n",
      "|(10,[0,7,8,9],[12...|  0.0|\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|[130.53,5.0,1.0,0...|  0.0|\n",
      "|(10,[0,5,7,8,9],[...|  0.0|\n",
      "|[147.86,0.0,1.0,0...|  0.0|\n",
      "|(10,[0,7,8,9],[14...|  0.0|\n",
      "|[150.16,5.0,1.0,0...|  0.0|\n",
      "|[176.85,2.0,0.0,0...|  0.0|\n",
      "|[180.76,5.0,1.0,0...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  653|\n",
      "|  1.0|   49|\n",
      "|  2.0|    3|\n",
      "|  3.0|   15|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Rain Intensity Testing Data\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_0 = rainIntensity_testData1.where(rainIntensity_testData1.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = rainIntensity_testData1.where(rainIntensity_testData1.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = rainIntensity_testData1.where(rainIntensity_testData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = rainIntensity_testData1.where(rainIntensity_testData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# # Sample smaller dataset as training data --> 5000 each class\n",
    "df_class_0_over = df_class_0.sample(fraction=0.11119,seed=234)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.03499,seed=456)\n",
    "df_class_2_over = df_class_2.sample(fraction=0.03723,seed=567)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.02576,seed=456)\n",
    "\n",
    "# # # Combine\n",
    "df_test_over = df_class_0_over.union(df_class_1_over)\n",
    "df_test_over = df_test_over.union(df_class_2_over)\n",
    "df_test_rainIntensity = df_test_over.union(df_class_3_over)\n",
    "df_test_rainIntensity.show()\n",
    "# Dataset label's classess ditribution after resampling\n",
    "df_test_rainIntensity.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2(3) T3 - Driver Wellbeing Resampling based on SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  A. Driver Wellbeing Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|    5|[10, 0, 0, 0, 4, ...|\n",
      "|    6|[13, 0, 0, 0, 0, ...|\n",
      "|    7|[190, 0, 0, 0, 0,...|\n",
      "|    4|[399, 0, 0, 0, 1,...|\n",
      "|    8|[716, 0, 0, 0, 0,...|\n",
      "|    7|[725, 4, 1, 0, 0,...|\n",
      "|    7|[773, 4, 1, 0, 0,...|\n",
      "|    4|[831, 2, 0, 1, 0,...|\n",
      "|    8|[874, 0, 0, 0, 0,...|\n",
      "|    4|[963, 4, 0, 1, 0,...|\n",
      "|    5|[974, 5, 0, 0, 0,...|\n",
      "|    7|[1072, 5, 1, 0, 0...|\n",
      "|    4|[1099, 0, 0, 0, 1...|\n",
      "|    7|[1108, 0, 4, 1, 0...|\n",
      "|    4|[1282, 0, 0, 0, 1...|\n",
      "|    8|[1386, 5, 1, 0, 0...|\n",
      "|    6|[1506, 5, 1, 0, 0...|\n",
      "|    5|[1606, 0, 0, 0, 1...|\n",
      "|    6|[1610, 4, 1, 0, 0...|\n",
      "|    5|[1671, 3, 0, 0, 0...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[91.0,2.0,0.0,0.0...|    2|\n",
      "|[18.0,0.0,0.0,0.0...|    2|\n",
      "|[87.0,0.0,0.0,0.0...|    2|\n",
      "|[137.0,0.0,0.0,0....|    2|\n",
      "|[65.0,0.0,0.0,0.0...|    2|\n",
      "|[119.0,1.0,0.0,0....|    2|\n",
      "|[91.0,2.0,0.0,0.0...|    2|\n",
      "|[39.0,0.0,0.0,0.0...|    2|\n",
      "|[158.0,1.0,0.0,0....|    2|\n",
      "|[100.0,2.0,0.0,0....|    2|\n",
      "|[95.0,3.0,0.0,0.0...|    2|\n",
      "|[39.0,0.0,0.0,0.0...|    2|\n",
      "|[30.0,0.0,0.0,0.0...|    2|\n",
      "|[91.0,2.0,0.0,0.0...|    2|\n",
      "|[12.0,0.0,0.0,0.0...|    2|\n",
      "|[45.0,0.0,0.0,0.0...|    2|\n",
      "|[98.0,1.0,0.0,0.0...|    2|\n",
      "|[118.0,0.0,0.0,0....|    2|\n",
      "|[145.0,0.0,0.0,0....|    2|\n",
      "|[39.0,0.0,0.0,0.0...|    2|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    2|  250|\n",
      "|    3|  238|\n",
      "|    4|  248|\n",
      "|    5|  256|\n",
      "|    6|  254|\n",
      "|    7|  259|\n",
      "|    8|  252|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "##### Input: Dataset with different number of multiple label classes\n",
    "##### Output: Dataset with same number of multiple label classes\n",
    "#######################\n",
    "def DriverWellbeing_SMOTE_PROCESS(training_dataset):\n",
    "    # Extract label and features\n",
    "    y = np.array(training_dataset.select('label').collect())\n",
    "    X = np.array(training_dataset.select('features').collect())\n",
    "    # Reshape array's size (SMOTE function only take 2d array)\n",
    "    new_X = X.reshape(X.shape[0],X.shape[2])\n",
    "    new_y = y.flatten()\n",
    "    ### Set number of class going to reach for specific class\n",
    "    ##Original dataset upsampling target number\n",
    "    #X_resampled, y_resampled = SMOTE(ratio={2: 25000}).fit_sample(new_X, new_y)\n",
    "    X_resampled, y_resampled = SMOTE(sampling_strategy={2: 250}).fit_resample(new_X, new_y)\n",
    "    \n",
    "    ## Transform dataframe into spark dataframe\n",
    "    xResample = X_resampled[:, newaxis,:]\n",
    "    yResample = y_resampled[:,newaxis]\n",
    "    xResample = xResample.astype(int)\n",
    "    yResample = yResample.astype(int)\n",
    "    ## Rebuild feature \n",
    "    featureSchema = StructType([\n",
    "      StructField(\"features\", ArrayType(IntegerType()), True),\n",
    "    ])\n",
    "\n",
    "    df_feature = spark.createDataFrame(xResample.tolist(),schema=featureSchema)\n",
    "    ## Rebulid label\n",
    "    labelSchema = StructType([\n",
    "      StructField(\"label\", IntegerType(), True),\n",
    "    ])\n",
    "    \n",
    "    df_label = spark.createDataFrame(yResample.tolist(),schema=labelSchema)\n",
    "    ## Combine two dataframe with a outter key\n",
    "    df1 = df_feature.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df2 = df_label.withColumn(\"id\", monotonically_increasing_id())\n",
    "    df_data = df2.join(df1, \"id\", \"outer\").drop(\"id\")\n",
    "    df_data.show()\n",
    "    ### Transform the feature type into vector(which can be regnonized by the training model)\n",
    "    list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "    df_data = df_data.select( \n",
    "    df_data[\"label\"],\n",
    "    list_to_vector_udf(df_data[\"features\"]).alias(\"features\")\n",
    "    )\n",
    "    return df_data\n",
    "\n",
    "### DriverWellbeing Training Data\n",
    "driverWellbeing_DF = DriverWellbeing_SMOTE_PROCESS(driverWellbeing_trainingData1)\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_2 = driverWellbeing_DF.where(driverWellbeing_DF.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = driverWellbeing_DF.where(driverWellbeing_DF.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = driverWellbeing_DF.where(driverWellbeing_DF.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = driverWellbeing_DF.where(driverWellbeing_DF.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "df_class_6 = driverWellbeing_DF.where(driverWellbeing_DF.label == 6).select(col(\"features\"),col(\"label\"))\n",
    "df_class_7 = driverWellbeing_DF.where(driverWellbeing_DF.label == 7).select(col(\"features\"),col(\"label\"))\n",
    "df_class_8 = driverWellbeing_DF.where(driverWellbeing_DF.label == 8).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# # Sample smaller dataset as training data --> 25000 each class\n",
    "df_class_3_over = df_class_3.sample(fraction=0.4,seed=123)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.127,seed=234)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.136,seed=456)\n",
    "df_class_6_over = df_class_6.sample(fraction=0.094,seed=567)\n",
    "df_class_7_over = df_class_7.sample(fraction=0.0797,seed=456)\n",
    "df_class_8_over = df_class_8.sample(fraction=0.187,seed=567)\n",
    "# # # Combine\n",
    "df_train_over = df_class_2.union(df_class_3_over)\n",
    "df_train_over = df_train_over.union(df_class_4_over)\n",
    "df_train_over = df_train_over.union(df_class_5_over)\n",
    "df_train_over = df_train_over.union(df_class_6_over)\n",
    "df_train_over = df_train_over.union(df_class_7_over)\n",
    "df_train_driverWellbeing = df_train_over.union(df_class_8_over)\n",
    "df_train_driverWellbeing.show()\n",
    "# Dataset label's classes distribution after resampling\n",
    "df_train_driverWellbeing.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### B. Driver Wellbeing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  2.0|   36|\n",
      "|  3.0|  420|\n",
      "|  4.0| 1305|\n",
      "|  5.0| 1240|\n",
      "|  6.0| 1697|\n",
      "|  7.0| 2101|\n",
      "|  8.0|  941|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Origianl dataset label's classes ditribution\n",
    "driverWellbeing_testData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[5.598,0.0,0.0,0....|  2.0|\n",
      "|[15.906,0.0,0.0,0...|  2.0|\n",
      "|[25.066,0.0,0.0,0...|  2.0|\n",
      "|(10,[0,4,6,7,8],[...|  2.0|\n",
      "|(10,[0,4,6,7,8],[...|  2.0|\n",
      "|[36.027,0.0,0.0,0...|  2.0|\n",
      "|[51.607,2.0,0.0,0...|  2.0|\n",
      "|[54.997,0.0,0.0,0...|  2.0|\n",
      "|[56.177,0.0,0.0,0...|  2.0|\n",
      "|[62.678,1.0,0.0,0...|  2.0|\n",
      "|[63.767,1.0,0.0,0...|  2.0|\n",
      "|[66.967,2.0,0.0,0...|  2.0|\n",
      "|[85.517,2.0,0.0,0...|  2.0|\n",
      "|[89.358,2.0,0.0,0...|  2.0|\n",
      "|[93.689,0.0,0.0,0...|  2.0|\n",
      "|[94.427,3.0,0.0,0...|  2.0|\n",
      "|[108.91,0.0,0.0,0...|  2.0|\n",
      "|[109.51,3.0,0.0,0...|  2.0|\n",
      "|[112.01,1.0,0.0,0...|  2.0|\n",
      "|[113.52,0.0,0.0,0...|  2.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  2.0|   36|\n",
      "|  3.0|   42|\n",
      "|  4.0|   50|\n",
      "|  5.0|   44|\n",
      "|  6.0|   52|\n",
      "|  7.0|   45|\n",
      "|  8.0|   48|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Driver Wellbeing Testing Data\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_2 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "df_class_6 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 6).select(col(\"features\"),col(\"label\"))\n",
    "df_class_7 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 7).select(col(\"features\"),col(\"label\"))\n",
    "df_class_8 = driverWellbeing_testData1.where(driverWellbeing_testData1.label == 8).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# # Sample smaller dataset as training data --> 4577 each class\n",
    "df_class_3_over = df_class_3.sample(fraction=0.11119,seed=234)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.03499,seed=456)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.03723,seed=567)\n",
    "df_class_6_over = df_class_6.sample(fraction=0.02576,seed=456)\n",
    "df_class_7_over = df_class_7.sample(fraction=0.02187,seed=567)\n",
    "df_class_8_over = df_class_8.sample(fraction=0.05159,seed=123)\n",
    "\n",
    "# # # Combine\n",
    "df_test_over = df_class_2.union(df_class_3_over)\n",
    "df_test_over = df_test_over.union(df_class_4_over)\n",
    "df_test_over = df_test_over.union(df_class_5_over)\n",
    "df_test_over = df_test_over.union(df_class_6_over)\n",
    "df_test_over = df_test_over.union(df_class_7_over)\n",
    "df_test_driverWellbeing = df_test_over.union(df_class_8_over)\n",
    "df_test_driverWellbeing.show()\n",
    "# Dataset label's classes distribution after resampling\n",
    "df_test_driverWellbeing.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2(4) T4 - **Driver Rush** Resampling based on SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### A. Driver Rush trainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0| 1013|\n",
      "|  1.0|  572|\n",
      "|  2.0| 1737|\n",
      "|  3.0| 6060|\n",
      "|  4.0|  999|\n",
      "|  5.0| 1488|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original dataset label's classes distribution\n",
    "driverRush_trainingData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10,[0,2,4,5,6],[...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,6],[6.43...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[11.087,0.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|[12.848,1.0,2.0,0...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|[15.319,0.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|[18.877,0.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[23.278,0.0,2.0,0...|  0.0|\n",
      "|[27.549,0.0,2.0,0...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  499|\n",
      "|  1.0|  508|\n",
      "|  2.0|  530|\n",
      "|  3.0|  496|\n",
      "|  4.0|  453|\n",
      "|  5.0|  518|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Driver Rush Training Data\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_0 = driverRush_trainingData1.where(driverRush_trainingData1.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = driverRush_trainingData1.where(driverRush_trainingData1.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = driverRush_trainingData1.where(driverRush_trainingData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = driverRush_trainingData1.where(driverRush_trainingData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = driverRush_trainingData1.where(driverRush_trainingData1.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = driverRush_trainingData1.where(driverRush_trainingData1.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# # Sample smaller dataset as training data --> 5000 each class\n",
    "# df_class_0_over = df_class_0.sample(fraction=0.0492,seed=123)\n",
    "# df_class_1_over = df_class_1.sample(fraction=0.0894,seed=234)\n",
    "# df_class_2_over = df_class_2.sample(fraction=0.02938,seed=456)\n",
    "# df_class_3_over = df_class_3.sample(fraction=0.00852,seed=567)\n",
    "# df_class_4_over = df_class_4.sample(fraction=0.0483,seed=456)\n",
    "# df_class_5_over = df_class_5.sample(fraction=0.0344,seed=567)\n",
    "\n",
    "# Smaller test dataset\n",
    "# # Sample smaller dataset as training data --> 5000 each class\n",
    "df_class_0_over = df_class_0.sample(fraction=0.492,seed=123)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.894,seed=234)\n",
    "df_class_2_over = df_class_2.sample(fraction=0.2938,seed=456)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.0852,seed=567)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.483,seed=456)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.344,seed=567)\n",
    "# # # Combine\n",
    "df_train_over = df_class_0_over.union(df_class_1_over)\n",
    "df_train_over = df_train_over.union(df_class_2_over)\n",
    "df_train_over = df_train_over.union(df_class_3_over)\n",
    "df_train_over = df_train_over.union(df_class_4_over)\n",
    "df_train_driverRush = df_train_over.union(df_class_5_over)\n",
    "df_train_driverRush.show()\n",
    "# Dataset label's classes distribution after resampling\n",
    "df_train_driverRush.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### B. Driver Rush Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  642|\n",
      "|  1.0|  386|\n",
      "|  2.0| 1094|\n",
      "|  3.0| 4044|\n",
      "|  4.0|  680|\n",
      "|  5.0|  954|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Original dataset label's classes distribution\n",
    "driverRush_testData1.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(10,[0,4,5,6,9],[...|  0.0|\n",
      "|[4.539,0.0,2.0,0....|  0.0|\n",
      "|[13.559,1.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[17.559,2.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|[39.317,1.0,2.0,0...|  0.0|\n",
      "|[46.867,0.0,2.0,0...|  0.0|\n",
      "|[48.757,2.0,0.0,0...|  0.0|\n",
      "|[51.579,0.0,2.0,0...|  0.0|\n",
      "|[56.027,3.0,0.0,0...|  0.0|\n",
      "|[58.467,2.0,2.0,0...|  0.0|\n",
      "|(10,[0,5,6,8,9],[...|  0.0|\n",
      "|[81.906,0.0,0.0,0...|  0.0|\n",
      "|[86.964,0.0,0.0,0...|  0.0|\n",
      "|[96.388,0.0,2.0,0...|  0.0|\n",
      "|(10,[0,4,6,8,9],[...|  0.0|\n",
      "|[106.97,5.0,2.0,0...|  0.0|\n",
      "|[115.29,2.0,0.0,0...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  205|\n",
      "|  1.0|  212|\n",
      "|  2.0|  185|\n",
      "|  3.0|  206|\n",
      "|  4.0|  178|\n",
      "|  5.0|  195|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Driver Rush Test Data\n",
    "### Resample the dataset\n",
    "# from pyspark.sql.functions import col\n",
    "df_class_0 = driverRush_testData1.where(driverRush_testData1.label == 0).select(col(\"features\"),col(\"label\"))\n",
    "df_class_1 = driverRush_testData1.where(driverRush_testData1.label == 1).select(col(\"features\"),col(\"label\"))\n",
    "df_class_2 = driverRush_testData1.where(driverRush_testData1.label == 2).select(col(\"features\"),col(\"label\"))\n",
    "df_class_3 = driverRush_testData1.where(driverRush_testData1.label == 3).select(col(\"features\"),col(\"label\"))\n",
    "df_class_4 = driverRush_testData1.where(driverRush_testData1.label == 4).select(col(\"features\"),col(\"label\"))\n",
    "df_class_5 = driverRush_testData1.where(driverRush_testData1.label == 5).select(col(\"features\"),col(\"label\"))\n",
    "\n",
    "# Original dataset test sampling parameter\n",
    "# df_class_0_over = df_class_0.sample(fraction=0.0294,seed=123)\n",
    "# df_class_1_over = df_class_1.sample(fraction=0.0532,seed=234)\n",
    "# df_class_2_over = df_class_2.sample(fraction=0.01767,seed=456)\n",
    "# df_class_3_over = df_class_3.sample(fraction=0.00511,seed=567)\n",
    "# df_class_4_over = df_class_4.sample(fraction=0.0293,seed=456)\n",
    "# df_class_5_over = df_class_5.sample(fraction=0.0205,seed=567)\n",
    "\n",
    "# Smaller dataset test sampling parameter\n",
    "df_class_0_over = df_class_0.sample(fraction=0.294,seed=123)\n",
    "df_class_1_over = df_class_1.sample(fraction=0.532,seed=234)\n",
    "df_class_2_over = df_class_2.sample(fraction=0.1767,seed=456)\n",
    "df_class_3_over = df_class_3.sample(fraction=0.0511,seed=567)\n",
    "df_class_4_over = df_class_4.sample(fraction=0.293,seed=456)\n",
    "df_class_5_over = df_class_5.sample(fraction=0.205,seed=567)\n",
    "# # # Combine\n",
    "df_test_over = df_class_0_over.union(df_class_1_over)\n",
    "df_test_over = df_test_over.union(df_class_2_over)\n",
    "df_test_over = df_test_over.union(df_class_3_over)\n",
    "df_test_over = df_test_over.union(df_class_4_over)\n",
    "df_test_driverRush = df_test_over.union(df_class_5_over)\n",
    "df_test_driverRush.show()\n",
    "# Dataset label's classes distribution after resampling\n",
    "df_test_driverRush.groupBy('label').count().sort('label').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Train & Test Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Original dataset train data and test data defination\n",
    "# rf_trainDF_driverWellbeing = df_train_driverWellbeing # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "# rf_test_DF_driverWellbeing = driverWellbeing_testData1\n",
    "# ### Rain Intensity Trainging and Test dataset\n",
    "# rf_trainDF_rainIntensity = df_train_rainIntensity # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "# rf_test_DF_rainIntensity = rainIntensity_testData1\n",
    "# ### Driver Rush Trainging and Test dataset\n",
    "# rf_trainDF_driverRush = df_train_driverRush # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "# rf_test_DF_driverRush = driverRush_testData1\n",
    "# ### Vehicle Speed Trainging and Test dataset\n",
    "# rf_trainDF_vehicleSpeed = df_train_vehicleSpeed # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "# rf_test_DF_vehicleSpeed = vehicleSpeed_testData1 # df_test_driverRush /df_test_driverWellbeing /df_test_rainIntensity /df_test_vehicleSpeed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Smaller dataset used only(Used for simply run through the whole process)\n",
    "### Driver Wellbeing Trainging\n",
    "rf_trainDF_driverWellbeing = df_train_driverWellbeing # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "\n",
    "### Rain Intensity Trainging\n",
    "rf_trainDF_rainIntensity = df_train_rainIntensity # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "\n",
    "### Driver Rush Trainging\n",
    "rf_trainDF_driverRush = df_train_driverRush # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "\n",
    "### Vehicle Speed Trainging\n",
    "rf_trainDF_vehicleSpeed = df_train_vehicleSpeed # df_train_driverRush /df_train_driverWellbeing /df_train_rainIntensity /df_train_vehicleSpeed\n",
    "\n",
    "### Test Dataset\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Train Models / Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest model(You can train the model if you want to, smaller dataset still need some time to do it\n",
    "                             # but it's much faster than training with the original dataset\n",
    "# rf_model_rainIntensity = rf.fit(rf_trainDF_rainIntensity)\n",
    "# rf_model_driverWellbeing = rf.fit(rf_trainDF_rainIntensity)\n",
    "# rf_model_driverRush = rf.fit(rf_trainDF_driverRush)\n",
    "# rf_model_vehicleSpeed = rf.fit(rf_trainDF_vehicleSpeed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Models\n",
    "rf_model_rainIntensity = RandomForestClassificationModel.load('../Models/RandomForest_RainIntensity')\n",
    "rf_model_driverRush = RandomForestClassificationModel.load('../Models/RandomForest_DriverRush')\n",
    "rf_model_driverWellbeing = RandomForestClassificationModel.load('../Models/RandomForest_DriverWellbeing')\n",
    "rf_model_vehicleSpeed = RandomForestClassificationModel.load('../Models/RandomForest_VehicleSpeed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.2.1**\n",
    "    Smaller Dataset Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = vehicleSpeed_testData1.sample(fraction=0.15,seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for random forest\n",
    "rf_predictions_rainInensity =  rf_model_rainIntensity.transform(test_df)\n",
    "\n",
    "# Predictions for random forest\n",
    "rf_predictions_driverWellbeing =  rf_model_driverWellbeing.transform(test_df)\n",
    "\n",
    "# Predictions for random forest\n",
    "rf_predictions_driverRush =  rf_model_driverRush.transform(test_df)\n",
    "\n",
    "# Predictions for random forest\n",
    "rf_predictions_vehicleSpeed =  rf_model_vehicleSpeed.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf_predictions_vehicleSpeed # the predictions you want to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Confusion Matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# True Label\n",
    "y_true = predictions.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "# predicted Label\n",
    "y_pred = predictions.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "\n",
    "# class\n",
    "class_temp = predictions.select(\"label\").groupBy(\"label\")\\\n",
    "                            .count().sort('count', ascending=False).toPandas()\n",
    "class_temp = class_temp[\"label\"].values.tolist()\n",
    "class_names = map(str, class_temp)\n",
    "\n",
    "# confusion matrixes\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred,labels=class_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[22  0  0  0  9  1  6  0 17  0]\n",
      " [ 1 48  0  0  2  0  0  0  0  0]\n",
      " [ 0  0 50  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 31 14  0  0  4  0  0]\n",
      " [ 1  0  0  1 37  0  0  0  9  0]\n",
      " [ 0  0  0  0  9 34  4  0  0  0]\n",
      " [ 4  0  0  0  4  6 30  0  1  0]\n",
      " [ 0  0  0  1  3  0  0 39  0  0]\n",
      " [ 0  0  0  0  6  0  4  0 33  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 34]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0AAAANHCAYAAAAfZj36AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzs3Xl8VNX9//HXCXvQkIDihnFDEVdUcMOllUWgWlfUfl1aq1JbrbvYWqWIUmtbW22tRaz1p91sQRS1CihVbN1F1MqmLIqIGxoCQtjP748JTAJBiAxzh9zX08c8yNx7M3nzedwZ/OSce26IMSJJkiRJaVCUdABJkiRJyhcbIEmSJEmpYQMkSZIkKTVsgCRJkiSlhg2QJEmSpNSwAZIkSZKUGo2TDiBJkiRJ6xNCeBdYAKwAlscYO4cQWgP/AHYG3gVOizFWfNnrOAIkSZIkaXPx9Rhjpxhj5+rnPwLGxhh3B8ZWP/9SNkCSJEmSNlcnAPdVf30fcOL6viHEGDdpIkmSJEnJalSyU4zLq5KOsU6x6tOJwOIam4bGGIfWPCaEMBOoACJwV4xxaAhhXoyxtMYxFTHGsi/7WV4DJEmSJDVwcXkVzTqclnSMdVr8+u8X15jWti5dY4xzQghtgSdDCFO+ys9yCpwkSZKkghdjnFP95yfAQ8DBwMchhO0Aqv/8ZH2vYwMkSZIkqaCFEFqGELZc9TXQE3gLeAT4dvVh3wZGru+1nAInSZIkNXgBwmY99rEN8FAIATI9zN9ijKNCCK8A/wwhnAfMAvqu74VsgCRJkiQVtBjjDGD/OrZ/BnSrz2tt1m2gJEmSJNWHI0CSJElSQxeAzPSx1HMESJIkSVJq2ABJkiRJSg2nwEmSJElpsHmvApczVkGSJElSatgASZIkSUoNGyBJkiRJqeE1QJIkSVIauAw24AiQJEmSpBSxAZIkSZKUGk6BkyRJkhq84DLY1ayCJEmSpNSwAZIkSZKUGk6BkyRJktLAVeAAR4AkSZIkpYgNkCRJkqTUcAqcJEmS1NAFXAWumlWQJEmSlBo2QJIkSZJSwylwkiRJUoMXXAWumiNAkiRJklLDBkiSJElSatgASZIkSUoNrwGSJEmS0sBlsAFHgCRJkiSliA2QJEmSpNRwCpwkSZKUBi6DDTgCJEmSJClFbIAkSZIkpYZT4CRJkqQGL7gKXDWrIEmSJCk1bIAkSZIkpYZT4CRJkqSGLuAqcNUcAZIkSZKUGjZAkiRJklLDKXCSJElSGrgKHOAIkCRJkqQUsQGSJEmSlBpOgZMkSZIaPG+EuopVkCRJkpQaNkCSJEmSUsMGSJIkSVJqeA2QJEmSlAZFIekEBcERIEmSJEmpYQMkSZIkKTWcAidJkiQ1dAGXwa5mFSRJkiSlhg2QJEmSpNRwCpwkSZKUBsFV4MARIEmSJEkpYgMkSZIkKTWcAidJkiQ1eMFV4KpZBUmSJEmpYQMkSZIkKTWcAidJkiSlgavAAY4ASZIkSUoRGyBJkiRJqWEDJEmSJCk1vAZIkiRJSgOXwQYcAZIkSZKUIjZAkiRJklLDKXCSJElSQxeCy2BXcwRIkiRJUmrYAEmSJElKDafASZIkSWngKnCAI0CSJEmSUqRBjgC1bNU6lm6zQ9IxCsK2WzZLOoJU0BYvW5l0hILRrIm/E1tl+YqYdISC0aSRF02vMq9qWdIRCkZpiyZJRygYr702fm6Mceukc2jDNcgGqHSbHfj+nQ8lHaMgXPW19klHkAratI++SDpCwdh56+KkIxSMuQuWJh2hYGxb2jzpCAVj5P8+SDpCwThhX3/RvEqLJuG9pDNsMFeBA5wCJ0mSJClFbIAkSZIkpUaDnAInSZIkqabgKnDVrIIkSZKk1LABkiRJkpQaNkCSJEmSUsNrgCRJkqQ0cBlswBEgSZIkSSliAyRJkiQpNZwCJ0mSJDV0AZfBrmYVJEmSJKWGDZAkSZKk1HAKnCRJktTgBafAVbMKkiRJklLDBkiSJElSajgFTpIkSUoDb4QKOAIkSZIkKUVsgCRJkiSlhlPgJEmSpDRwFTjAESBJkiRJKWIDJEmSJCk1bIC+orfGPcFfrv8evzjjCG48fn/+8IMTefPfj67ev3jhAsbedztDLj6Fm044gFtOO4y/DfwBc2fPTDB1fk2eNInePbvRuqSYXcq3Z9DAAaxYsSLpWImwFlnWImvsqEc5ucehHLhbG3odvg/3Df1d0pESMX36NC656EIO63IArYqb0LvHMUlHStTy5cv5w+2/5OsH70OHHVpx2H67ceN1VycdKxFp/Lz4aNZM7r7pGvqf3oNvdS7nhgtOrbV/4qvPc8aB7ep8/OwHZyaUOn/SeE7kVAiF+8gjrwH6ip5/8E+UbtuO3t+/lpYlZbz98jiG3XwFi+ZXcOiJ51D5yYeMf/yfHNj7VLqfeznLlizm2b8P4a4fnsrFdz1Gq7bbJf1X2KQqKiro06s7HTvuxbARI5kxfTo/6n8lK1euZOCgm5KOl1fWIstaZE145QUu73cmJ51+NlddN5g3J7zKbTcPoKioiLPPvyjpeHk1edJExox6gi6HHMLSpUuTjpO4qy/px/PPPs2lV/+EXdt34MM5s5k2dXLSsfIurZ8Xs2e8zYTn/s3u+x7I8mXL1tq/y577cuP/G1lr29yP5nD7j75Pp65fz1fMRKT1nFDu2QB9RWfeeBctW7Ve/XzXAw5j/mcf89yD93LoiedQtm07Lr9/LE2aNV99zE77dObWM49m/OjhHHP2D5OInTd/HDqExVVVPDBsBCUlJXTr3oP5C+YzeNBArriqPyUlJUlHzBtrkWUtsobcdgsHdDmMG375ewAOP7ob8ysrGHLbLZxxzgU0ado04YT50+cbx3Pc8ScAcNa3+vLZ3M8STpSccWPH8NhDw3j8mZfZvUPHpOMkKq2fFwce1YPOXzsWgF9f3Y8F8z6vtb94iy3Zfb+Dam2bMuFlQlERh/Y8Lm85k5DWc0K55xS4r6hm87PK9u33YuG8zD/cTVsU12p+AIpLSmm1zfYsrGj4/7iPHvUE3XseW+vDqO9pZ1BVVcV/nh2XYLL8sxZZ1iJryqQ3OfTI2r+tPfyoTBP0+viXE0qVjKIi/yla5Z9/u4/Djvha6psfSO/nxVd5Pzw3eiR7HXgorbfedhMkKhxpPSeUe/6rk0OzJk2gbXn7de5fOO8zPp/zHm13WvcxDcXbU6fQocOetbaVl5dTXFzM1KlTEkqVDGuRZS2yli5ZQpMmTWpta9qsGQAzp01NIpIKwOuvvcIuu7VnwDWXse8ubelY3poLv3M6H380J+loeefnxYb5cNYM3p3yFof3OiHpKJuc58RGCiGzDHahPvLIBihHpr/2PFOef4qDv7nuCxCfuOvnNG3ekn2//o08JktGRUUFrVqVrrW9tKyMeRUVCSRKjrXIshZZO+68KxPfeK3Wtv+9/ioAlWtMeVF6zP3kYx584C9MfutNfjv0fn55+138740JfO/bpxNjTDpeXvl5sWGeHzWSRo2bcEi3PklH2eQ8J5QrXgOUAxUfzWbYzVew5+HdOfDYU+o85uVH/8qbY0dyxoA7KC4py3PCZIQ6VvSIMda5vaGzFlnWIuO0s77LTddezvC/3UuPPify1uvjub96FbiiRo0STqekxBiJMTL0z8Moa90GgK232Y4zTujB8/95hq5HNeyL3Nfk58X6PT/6EfY79Ci2aOX/W0gbyhGgjbRo/jzuv/Y8Sttuz6nX/KrOYyY/P5Z/3XEjPc+/mr2O6JnnhMkoKyujsnLeWtvnV1bSqnTt3940ZNYiy1pknXT6OfQ96zxuuvZyjti3nMv7ncn3LvsRAG22aptwOiWlpLSMDnvtvbr5Aehy6OE0bdqUd1K2EpyfF+v33tuT+GDmO3RNwfQ38JzIiaSXunYZ7IwQwrvAAmAFsDzG2HmN/QG4HegDLAK+E2N8bc3XScLSxVX85fp+rFi+jLNuupumLYrXOmbWxNcY9rPL6HLctzjitAsSSJmMPTrsudZ83Pfff5+FCxeuNX+3obMWWdYiq1GjRvzkplu5+Krr+PjDObQr34mZ094GYL8DuyScTklpv3sHli5dstb2GGPqFovw82L9nh89kqbNm69eNa6h85xQrhTKp+nXY4yd1mx+qvUGdq9+9AP+kNdk67BixXL+ceMP+eyDdznnZ/ewRVmbtY75+N13+Mv1/Wjf+Uj6XHR9AimTc2yv3jw1ZjQLFixYvW34sH/QokULjjzq6AST5Z+1yLIWa2tVWsYeHfemuOUWPHD/3XTqfAi7tu+QdCwl5JievZky6S0+/2zu6m0vv/Bfli1bRse9900wWf75ebF+L4x5lAOP7EHz4pZJR8kLzwnlSuIjQBvgBOD+mLn688UQQmkIYbsY44dJhnrstwN5++Vx9PnBdVTNn8f7kyas3rdd+71YvPAL7r/2uzRtXsxhJ32bD6a8sXp/s5Zb0Han3ZOInTfn97uQO+/4LWf0PZkrr76GmTNmMHjQQC657IrUrdNvLbKsRdYbr73MhJdfoMPe+7Hwi/k8PnI4z48by30jxiQdLe8WLVrEmFGPAzBnzhwWzJ/PwyOGA9CzVx+Ki9ceXW+ovnXOedx3952cf9Yp/OCy/iz8YgG3DLqOrkcfQ5dDuyYdL6/S+nmxpKqKCc+NBaDik4+oWvgFLz71GAAHdO1GsxYtAHjnzfF88sEszr5iQGJZ8y2t50Quea1URiE0QBEYE0KIwF0xxqFr7N8BeL/G89nV22o1QCGEfmRGiGjVdvtNl7batPH/BeDxO9e+8/AVf36aeR9/wPxPPwLgT1edVWv/zvsdzHm3/nWTZ0xSWVkZj48ey+WXXswpJx5PaWkpP7z0cq4bMDDpaHlnLbKsRVbjxk0Y9egI7vzNzRQVFXHgwYdx/4gn2aPj3klHy7tPP/mEs//v9FrbVj1/a8p0dtp55wRSJWPLLUv464hR3HDtlVzS7xyaNGlKj17Hcf1Nv0g6Wt6l9fOismIut/W/sNa2Vc9/+9gLtG2xI5BZ/KB4ixI6dU3PwhhpPSeUeyHpZTVDCNvHGOeEENoCTwI/jDE+W2P/v4CbY4z/rX4+FugfYxy/rtfcYY994/fvfGhTR98sXPW1hn/PIWljTPvoi6QjFIydt07PSMv6zF2wNOkIBWPb0ubrPyglRv7vg6QjFIwT9t0h6QgFo0WTMH4dl3EUlKKynWPzYwp3xLBqxHl5q2PiI0AxxjnVf34SQngIOBh4tsYhs4EdazxvB6TvjnCSJEnSVxRwCtwqiS6CEEJoGULYctXXQE/grTUOewQ4J2QcClQmff2PJEmSpM1T0iNA2wAPVXejjYG/xRhHhRAuBIgxDgEeJ7ME9jQyy2Cfm1BWSZIkSZu5RBugGOMMYP86tg+p8XUELspnLkmSJKlBCdUPFcx9gCRJkiRpk7MBkiRJkpQaNkCSJEmSUiPpRRAkSZIkbXLBZbCrOQIkSZIkKTVsgCRJkiSlhlPgJEmSpBRwClyGI0CSJEmSUsMGSJIkSVJqOAVOkiRJSgGnwGU4AiRJkiQpNWyAJEmSJKWGU+AkSZKkFHAKXIYjQJIkSZJSwwZIkiRJUmo4BU6SJElq6EL1Q44ASZIkSUoPGyBJkiRJqeEUOEmSJKmBCwRXgavmCJAkSZKk1LABkiRJkpQaNkCSJEmSUsNrgCRJkqQU8BqgDEeAJEmSJKWGDZAkSZKk1HAKnCRJkpQCToHLcARIkiRJUmo0yBGgbbZsxmVH7pp0jIJQdvRPko5QMCrGDU46ggpQu9Ytko5QMBo38ndiq2xb2jzpCCpAJ+y7Q9IRJOVAg2yAJEmSJNXmFLgMf90nSZIkKTVsgCRJkiSlhlPgJEmSpIYuVD/kCJAkSZKk9LABkiRJkpQaToGTJEmSUsBV4DIcAZIkSZKUGjZAkiRJklLDBkiSJElSangNkCRJktTABYLXAFVzBEiSJElSatgASZIkSUoNp8BJkiRJKeAUuAxHgCRJkiSlhg2QJEmSpNRwCpwkSZKUBs6AAxwBkiRJkpQiNkCSJEmSUsMpcJIkSVJDFxrGKnAhhEbAq8AHMcbjQgi7AA8ArYHXgLNjjEu/7DUcAZIkSZK0ubgUmFzj+S3Ab2KMuwMVwHnrewEbIEmSJEkFL4TQDvgG8Mfq5wE4Bhhefch9wInrex0boByaPn0al1x0IYd1OYBWxU3o3eOYpCMlYvutSvj0yQFUPTeYli2art6+bZstuevak5n+8DV8+uQAXrj3Is7ouX+CSfNn8qRJ9O7ZjdYlxexSvj2DBg5gxYoVScdKhLXIeHjEcL7V90T2al9Ou7at+FrXgxn+zweSjpUYz4ssa5FlLTKsQ5a12DghhIJ9AFuFEF6t8ehXx1/hNqA/sLL6eRtgXoxxefXz2cAO66uD1wDl0ORJExkz6gm6HHIIS5d+6dTDBu1nF/Xii6qlbFHcbPW2EALDbzmL1iXF/OTOUXz02QJO+vo+3PvT01i0eBmPPDspwcSbVkVFBX16dadjx70YNmIkM6ZP50f9r2TlypUMHHRT0vHyylpk3fm731C+0y4MvuVW2rRpw5Ojn+CCc8/i88/m0u/7FycdL688L7KsRZa1yLAOWdaiwZsbY+y8rp0hhOOAT2KM40MIX1u1uY5D4/p+kA1QDvX5xvEcd/wJAJz1rb58NvezhBPlX9f9d6LHobvzy/vHcfPFvVdv333HNhzUsR2n9P8zjz83BYBnxs+gy1470rf7vg26Afrj0CEsrqrigWEjKCkpoVv3HsxfMJ/BgwZyxVX9KSkpSTpi3liLrL8PG0mbrbZa/fyorx3Dhx9+yO9/d1vqGiDPiyxrkWUtMqxDlrVIva7AN0MIfYDmQAmZEaHSEELj6lGgdsCc9b2QU+ByqKgo3eUsKgrcevnx3Hzv08ytXFhrX5PGjQCo/GJxre2VX1QRGvhduUaPeoLuPY+t9cHc97QzqKqq4j/PjkswWf5Zi6yazc8q++3fibmffpJAmmR5XmRZiyxrkWEdsqxFusUYfxxjbBdj3Bk4A/h3jPFM4Gng1OrDvg2MXN9rpfv/2JVTF5x4MM2bNmbIgy+utW/ijI95eeIsBpzfjd3atWHL4mac1ecADtt3J+5++OUE0ubP21On0KHDnrW2lZeXU1xczNSpUxJKlQxr8eVefukFOuy5V9Ix8s7zIstaZFmLDOuQZS02XtLX+aznGqCv6hrgihDCNDLXBN2zvm9wCpxyonVJCwZc0J3vDhrG8hUr6zzmhCvvY9jPz+Ktf1wBwNJly/nez0Yw7rUZ+YyadxUVFbRqVbrW9tKyMuZVVCSQKDnWYt3GPT2Wxx97hDv+8Meko+Sd50WWtciyFhnWIctaaJUY4zPAM9VfzwAOrs/32wApJwZ+ryevTJzN6BfernN/CIF7ru9L61bFnHX93/mkYiG9DtuDP/zoJD6rXMSTL72T58T5VddvNmKMDeKGZPVlLdY26713ueDcs+lz3Df5v7O/nXScRHheZFmLLGuRYR2yrIVywQZIG63jLm359jcOpMdFf6TVFs0BKG6WWf66VcvmrFixkm4Ht6dP1z3Z5/RfM312ZnGI/0yYSbu2rRj8g14NugEqKyujsnLeWtvnV1bSqnTt32Q1ZNZibRWff07fk46j3Y7l3HXP/UnHSYTnRZa1yLIWGdYhy1psnMBGTzVrMBJvgEIIlwPnk1my7n/AuTHGxTX2NwPuBw4CPgNOjzG+m0BUrUP7dm1o2qQx44ZeuNa+6SOv4d5HX2XarLksrFq6uvlZ5Y23P+QbR3TMV9RE7NFhz7XmJr///vssXLhwrbnMDZ21qG3RokWcfuo3Wbp0KY+NeoSWLVsmHSkRnhdZ1iLLWmRYhyxroVxJdBGEEMIOwCVA5xjjPkAjMqs61HQeUBFjbA/8Brglvym1Ps+/+R49L/5jrcev/pxZjeWEK+/jN3/7D7M+nkfLFk3Zvbz2ylcH7Lk9733UsOftHturN0+NGc2CBQtWbxs+7B+0aNGCI486OsFk+WctspYvX853zjqdGdOnMeyhx9i6bdukIyXG8yLLWmRZiwzrkGUtlCuFsApcY6BFCKExUMzaa3efANxX/fVwoFso0PG7RYsW8fCI4Tw8Yjhz5sxh7txPVz9ftGhR0vE2mc8qF/GfCTNrPabO+hSA5954l3dmzWXUC1OZ9VEF/7z5TE7rvh9f77wbv7ikD6d224+7Hnwp4b/BpnV+vwtp1qwZZ/Q9mX+PfYp77h7K4EEDueSyK1J3zwJrkXXVZRfz5OgnuPqan1BR8TmvvPzi6seSJUuSjpdXnhdZ1iLLWmRYhyxrkQOhgB95FGJc781SN22AEC4FBgNVwJjq9bxr7n8L6BVjnF39fDpwSIxx7hrH9QP6Aey4Y/lBk96ZmY/4tbz37rvss+dude57a8p0dtp55/wGArY+5vq8/0yAs/ocwN0/OZWtut/AwqqlAOy6Q2tuvLAnh+23E1sWN2PGB58z9KGXuGfkK3nJVDFucF5+Tl0mT5rE5ZdezEsvvkBpaSnf+e75XDdgII0aNUosU1IKrRaLl65I5Ofu13E33p/1Xp373pg0jfKdds5vIKB50+TOx0I7L5JkLbKsRYZ1yCrEWrRoEsbHGDsnFmADNd26fdzqlF8kHWOdPrzrlLzVMdEGKIRQBjwInA7MA4YBw2OMf6lxzETg2DUaoINjjJ/V8ZIAHHhQ5/js8w373jIbKqkGqBAl2QCpcCXVABWiJBsgSdpc2QDlRj4boKSnwHUHZsYYP40xLgNGAIevccxsYEeA6mlyrYDP85pSkiRJ2pyFBnsj1HpLugGaBRwaQiiuvq6nGzB5jWMeAVbdGONU4N8x6Xl7kiRJkjZLiTZAMcaXyCxs8BqZJbCLgKEhhEEhhG9WH3YP0CaEMA24AvhRImElSZIkbfYSvw9QjPGnwE/X2Dygxv7FQN+8hpIkSZIamAJdSDnvkp4CJ0mSJEl5YwMkSZIkKTUSnwInSZIkadNzClyGI0CSJEmSUsMGSJIkSVJq2ABJkiRJSg2vAZIkSZLSwEuAAEeAJEmSJKWIDZAkSZKk1HAKnCRJkpQCLoOd4QiQJEmSpNSwAZIkSZKUGk6BkyRJkhq4EIJT4Ko5AiRJkiQpNWyAJEmSJKWGU+AkSZKkFHAKXIYjQJIkSZJSwwZIkiRJUmo4BU6SJElKAafAZTgCJEmSJCk1bIAkSZIkpYYNkCRJkqTU8BogSZIkKQ28BAhwBEiSJElSitgASZIkSUoNp8BJkiRJKeAy2BmOAEmSJElKjQY5AhSAxo3s7QAqxg1OOkLBKOtycdIRCkbFK3ckHaFgNG/aKOkIkiQpjxpkAyRJkiSphuAUuFUcJpEkSZKUGjZAkiRJklLDKXCSJElSAxcAZ8BlOAIkSZIkKTVsgCRJkiSlhlPgJEmSpAYvuApcNUeAJEmSJKWGDZAkSZKk1HAKnCRJkpQCzoDLcARIkiRJUmrYAEmSJElKDRsgSZIkSanhNUCSJElSCrgMdoYjQJIkSZJSwwZIkiRJUmo4BU6SJElq6ILLYK/iCJAkSZKk1LABkiRJkpQaToGTJEmSGrgAFBU5Bw4cAZIkSZKUIjZAOTZ50iR69+xG65JidinfnkEDB7BixYqkYyUijbU46/hDqJpwx1qP8089otZxV3+3J+88cSOfv/BrnrznMvbbY4eEEudfGs+LdbEWWdYiy1pkWYsM65BlLZQLToHLoYqKCvr06k7HjnsxbMRIZkyfzo/6X8nKlSsZOOimpOPlVdprcewFt7N4ybLVz2fOnrv666u+25MfX9CLa297mKnvfswlZx3Dv4b8kM59B/PxZwuSiJs3aT8varIWWdYiy1pkWYsM65BlLTaeq8Bl2ADl0B+HDmFxVRUPDBtBSUkJ3br3YP6C+QweNJArrupPSUlJ0hHzJu21GD/xPRZWLV1re7OmjbnqOz345b1jGPKPZwF46Y2ZTHn8Bi48/WhuuPOxfEfNq7SfFzVZiyxrkWUtsqxFhnXIshbKFafA5dDoUU/Qveextd6AfU87g6qqKv7z7LgEk+WftajbofvvSqstW/DgmAmrty1avJTHx71Fz657JZgsPzwvsqxFlrXIshZZ1iLDOmRZC+WKDVAOvT11Ch067FlrW3l5OcXFxUydOiWhVMlIey0mPjqQBa/czhsPXc95p3Rdvb3DztuwfPkKps36pNbxU2d+RIddtsl3zLxL+3lRk7XIshZZ1iLLWmRYhyxrsfFCCAX7yCenwOVQRUUFrVqVrrW9tKyMeRUVCSRKTlpr8dHc+Qz8/aO8+tZ7NGpUxGm9DuKO675FcfOm/O6vT1NaUswXVUtYuTLW+r6KBYto2aIZTRo3YtnyhnsxZ1rPi7pYiyxrkWUtsqxFhnXIshbKFRugHKurg40x5r2zLQRprMVTL0zmqRcmr34+5rlJNGvSmGvO78Udf3sGgBjX/r5ApiaROnY2MGk8L9bFWmRZiyxrkWUtMqxDlrVQLjgFLofKysqorJy31vb5lZW0Kl37NxYNmbXIeuip12lT2pKdtm/NvPmL2LK42Vo3IivdsgULq5awfPnKhFLmh+dFlrXIshZZ1iLLWmRYhyxroVxJvAEKIVwaQngrhDAxhHBZHftDCOG3IYRpIYQ3QwgHJpFzQ+zRYc+15qC+//77LFy4cK05qw2dtVhbjDD13Y9p3LgRu+24da19e+yyDVNnfpxQsvzxvMiyFlnWIstaZFmLDOuQZS02Usgsg12oj3xKtAEKIewDXAAcDOwPHBdC2H2Nw3oDu1c/+gF/yGvIeji2V2+eGjOaBQuy93IZPuwftGjRgiOPOjrBZPlnLbJO7N6JTysWMOvDz3nxjRlULqji5B4HrN7fonkT+hy1L2Oem5RgyvzwvMiyFlnWIstaZFmLDOuQZS2UK0mPAHUEXowxLooxLgfGASetccwJwP0x40WgNISwXb6Dbojz+11Is2bNOKPvyfx77FPcc/dQBg8ayCWXXZG6tenTWou//+p8rvxOd3p23YveR+7DPTeeQ99jD+LmoaOIMbJk6XJ+9f+epP93j+V7px3F1w7eg7/+4jwnrM2aAAAgAElEQVSKQuAPDzT8JTzTel7UxVpkWYssa5FlLTKsQ5a1UK6EWNcV2fn64SF0BEYChwFVwFjg1RjjD2sc8xjw8xjjf6ufjwWuiTG+uq7XPeigzvG5l9a5e5OaPGkSl196MS+9+AKlpaV857vnc92AgTRq1CiRPEkqtFqUdbl4k/+MGy4+nhO7daLdNmWEAJNnfMQdf3uav//rlVrH9T/vWPr1PYLWrVry2qRZXPmL4bwxdfYmz7dKxSt35O1nranQzoskWYssa5FlLbKsRYZ1yCrEWrRoEsbHGDsnFmADFW+/R2x//p1Jx1in/93YI291TLQBAgghnAdcBHwBTAKqYoyX19j/L+DmNRqg/jHG8Wu8Tj8yU+TYsbz8oLenv5env4E2F/logDYXSTZAkiQ1JDZAuZHPBijpKXDEGO+JMR4YYzwK+Bx4Z41DZgM71njeDphTx+sMjTF2jjF23nqrrdfcLUmSJEnJ3wcohNA2xvhJCKEcOJnMdLiaHgEuDiE8ABwCVMYYP8x3TkmSJGnzFbxfUrXEGyDgwRBCG2AZcFGMsSKEcCFAjHEI8DjQB5gGLALOTSypJEmSpM1a4g1QjPHIOrYNqfF1JHONkCRJkiRtlMQbIEmSJEmbnjPgMhJfBEGSJEmS8sUGSJIkSVJqOAVOkiRJSgFXgctwBEiSJElSatgASZIkSUoNGyBJkiRJqeE1QJIkSVJDF1wGexVHgCRJkiSlhg2QJEmSpNRwCpwkSZLUwAVcBnsVR4AkSZIkpYYNkCRJkqTUcAqcJEmSlALOgMtwBEiSJElSatgASZIkSUoNp8BJkiRJKeAqcBmOAEmSJElKDRsgSZIkSanhFDhJkiQpBZwBl+EIkCRJkqTUsAGSJEmSlBpOgZMkSZIauuAqcKs4AiRJkiQpNWyAJEmSJKWGDZAkSZKk1PAaIEmSJKmBC7gM9iqOAEmSJElKDUeAlBoVr9yRdISCcdyQF5KOUDB+3H33pCMUjK7tt0o6ggrQvIVLk45QMEpbNk06gqQcsAGSJEmSGrzgMtjVnAInSZIkKTVsgCRJkiSlhlPgJEmSpBRwBlyGI0CSJEmSUsMGSJIkSVJqOAVOkiRJSgFXgctwBEiSJElSatgASZIkSUoNp8BJkiRJDV1wFbhVHAGSJEmSlBo2QJIkSZJSwwZIkiRJUmp4DZAkSZLUwAVcBnsVR4AkSZIkpYYNkCRJkqTUcAqcJEmSlAJOgctwBEiSJElSatgASZIkSUoNp8BJkiRJKeAMuAxHgCRJkiSlhg1Qjk2eNInePbvRuqSYXcq3Z9DAAaxYsSLpWImwFllprMWRu7Xm9lP2YcT5nXn8wkO498xOnNl5BxoXZX/99M19tmHwcXsy4vzOPHXxYey/Q0mCiTetD96bwW9+eiX9TvwaPffehivOOeFLj7/zZz+he8etuesXP81TwmSl8T2yLtZibR/O+YDddmjNdqXNWPjFF0nHyTvPiSxroVxwClwOVVRU0KdXdzp23IthI0YyY/p0ftT/SlauXMnAQTclHS+vrEVWWmtR0rwxr39QyT8nzOGLJcvZc5stOOfgHSkrbsodz84EoMeeWxOBV2dVcsweWyUbeBN7d9pUXn72KTrufxDLly390mPfmzaVUSP+RvEWW+YpXbLS+h6pi7Wo240DfkzLlluwaOHCpKPknedElrXYeK4Cl2EDlEN/HDqExVVVPDBsBCUlJXTr3oP5C+YzeNBArriqPyUlDfe322uyFllprcW/Jn5S6/kbH8ynuGkjTth329UN0CXD3yICO7du0eAboMO+fixdu/UG4IZLz6Wy4vN1HnvH4Gs56ex+PPXIsHzFS1Ra3yN1sRZre/H5//L0U2O45Mr+DLr+x0nHyTvPiSxroVxxClwOjR71BN17HlvrDdj3tDOoqqriP8+OSzBZ/lmLLGuRNX/x8lpT4GKCWfKtqGjDPm6fHf0Is2a8zRkXXLKJExUO3yNZ1qK2FStWcF3/y7m8/7W0bt2wf0myLp4TWdZCuWIDlENvT51Chw571tpWXl5OcXExU6dOSShVMqxFVtprURSgWeMi9tluS07ab1sefevjpCMVrCWLqxhyy085/4rraVHcMuk4eZP290hN1qK2+/80lMVLFnPuBd9POkpiPCeyrMVGCplV4Ar1kU9OgcuhiooKWrUqXWt7aVkZ8yoqEkiUHGuRlfZaPPa9Q2jaOPO7ljFTPmHoc+8lnKhw/X3o7bTeehu6f7Nv0lHyKu3vkZqsRdbnn3/GLwbfwB1D76VJkyZJx0mM50SWtVCu2ADlWF0Xl8UYU3nRmbXISnMtLnnwLZo3LqLDNltwdpd2/PDolfx23MykYxWcD2e/x7B77+SX945IxXmxpjS/R9ZkLTJ+fuMADujchW49eycdJXGeE1nWQrlgA5RDZWVlVFbOW2v7/MpKWpWu/RuLhsxaZKW9FtM+zaza9NaHC5hftYxreuzOsAlz+HD+koSTFZY/3nojXY48hvJdd+eL+ZUArIwrWbp0CV/Mr6TlliUN9h/4tL9HarIWGVMnT+KBv9zHQ4+PpXJeph5VVYsAmD+/kqJGjWjRokWSEfPGcyLLWmycQGiw/47UV6INUAhhR+B+YFtgJTA0xnj7GscE4HagD7AI+E6M8bV8Z90Qe3TYc605qO+//z4LFy5ca85qQ2ctsqxF1jvVzdB2Jc1tgNYw+91pTJ8ykf8++a9a20f+9R5G/vUe/v70G2y97fYJpdu0fI9kWYuMGdPfYdmyZRzX46i19h24167839nncuvvhiSQLP88J7KshXIl6RGg5cCVMcbXQghbAuNDCE/GGCfVOKY3sHv14xDgD9V/Fpxje/XmN7f+kgULFrDllpn7dwwf9g9atGjBkUcdnXC6/LIWWdYia+/tMn//D+cvTjhJ4bnixtuoWlT7HieDr7yA/TofzvHfOpdWrdsklGzT8z2SZS0yDj6sKw8+OqbWtqfHjuGO237FX4aNZKedd0koWf55TmRZC+VKog1QjPFD4MPqrxeEECYDOwA1G6ATgPtjjBF4MYRQGkLYrvp7C8r5/S7kzjt+yxl9T+bKq69h5owZDB40kEsuuyJ1a9Nbi6y01uLm4zvy2ux5vPtZFStjZO/ttqRvp+15+u25q0d/9mjbkm22bEbbLZoBsN/2JZQ0b8zHC5bw9icN64aHi6sW8fKzTwEw9+OPWPTFAp4d/QgABx/VnQ77dFrre5o2bU7b7Xag08Fd85o139L6HqmLtcho02YrDj+y9v/Qvj8rs4DKoYcdQcsttkgiViI8J7KshXIl6RGg1UIIOwMHAC+tsWsH4P0az2dXbyu4BqisrIzHR4/l8ksv5pQTj6e0tJQfXno51w0YmHS0vLMWWWmtxdRPvqDnnm3ZdstmrIiRDysXc8+Ls2otg33CvttybMe2q59/+5AdARg9+RN+OXZ63jNvSvM+n8ugy86rtW3V8788NZ5tdyhPIlZBSOt7pC7WQmvynMiyFhvPS4AyQmZgJeEQIWwBjAMGxxhHrLHvX8DNMcb/Vj8fC/SPMY5f47h+QD+AHcvLD3p7ukvtSuty3JAXko5QMH7cffekIxSMru3TeaNJfbl5C5cmHaFglLZsmnQEFaAWTcL4GGPnpHOsT0l5x9jl6j8lHWOd/n3J4XmrY+I3Qg0hNAEeBP66ZvNTbTawY43n7YA5ax4UYxwaY+wcY+y89VZbb5qwkiRJkjZrSa8CF4B7gMkxxl+v47BHgItDCA+QWfygshCv/5EkSZIKWZFz4IDkrwHqCpwN/C+E8Hr1tmuBcoAY4xDgcTJLYE8jswz2uQnklCRJktQAJL0K3H+BL21Fq1d/uyg/iSRJkiQ1ZEmPAEmSJEnKA2fAZSS+CIIkSZIk5YsNkCRJkqTUcAqcJEmS1MCFAME5cIAjQJIkSZJSxAZIkiRJUmo4BU6SJElKgSJnwAGOAEmSJElKERsgSZIkSalhAyRJkiQpNbwGSJIkSUqBzXkZ7BBCc+BZoBmZHmZ4jPGnIYRdgAeA1sBrwNkxxqVf9lqOAEmSJEkqdEuAY2KM+wOdgF4hhEOBW4DfxBh3ByqA89b3QjZAkiRJkgpazPii+mmT6kcEjgGGV2+/Dzhxfa/lFDhJkiQpBTbjGXAAhBAaAeOB9sDvgenAvBjj8upDZgM7rO91HAGSJEmSlLStQgiv1nj0W/OAGOOKGGMnoB1wMNCxjteJ6/tBjgBJkiRJStrcGGPnDTkwxjgvhPAMcChQGkJoXD0K1A6Ys77vdwRIkiRJauACEAr4v/XmD2HrEEJp9dctgO7AZOBp4NTqw74NjFzfazkCJEmSJKnQbQfcV30dUBHwzxjjYyGEScADIYSbgAnAPet7IRsgSZIkSQUtxvgmcEAd22eQuR5og9kASZIkSSlQtJmvApcrXgMkSZIkKTVsgCRJkiSlhlPgJEmSpIYuBMLmfifUHHEESJIkSVJq2ABJkiRJSg0bIEmSJEmp4TVAkiRJUgp4CVCGI0CSJEmSUqNBjgBFYPmKlUnHKAiNG9njam0PX3BI0hEKRqefjE46QsF46+e9k46gAlTasmnSEQrGtI++SDpCwWi/7RZJR5C+sgbZAEmSJEnKCkCRc+AAp8BJkiRJShEbIEmSJEmp4RQ4SZIkKQWcAZfhCJAkSZKk1LABkiRJkpQaToGTJEmSUiA4Bw5wBEiSJElSitgASZIkSUoNp8BJkiRJDVwIrgK3iiNAkiRJklLDBkiSJElSajgFTpIkSUqBIufAAY4ASZIkSUoRGyBJkiRJqWEDJEmSJCk1vAZIkiRJSgGvAMpwBEiSJElSatgASZIkSUqNdU6BCyG8+RVfM8YY9/+K3ytJkiRpEwgugw18+TVA2wMxX0EkSZIkaVNb5xS4GONWMcatv8ojn3+BQjJ9+jQuuehCDutyAK2Km9C7xzFJR0rU5EmT6N2zG61LitmlfHsGDRzAihUrko6VCGuRkdb3SK/9tuWfFx/KKzd0Y+LNPRnT/0h+0G03mjTK/CbukN1aM+1Xvet83HtB54TT54fvkSxrkWUtMsaOepSTexzKgbu1odfh+3Df0N8lHSkxnhPKBVeBy6HJkyYyZtQTdDnkEJYuXZp0nERVVFTQp1d3Onbci2EjRjJj+nR+1P9KVq5cycBBNyUdL6+sRVZa3yOlxU14cdpn3P3MTBZULWO/8lIu6dmerUuaccNDk5g4ez6n/vaFWt+zfVlzfnv2AYybMjeh1PnjeyTLWmRZi4wJr7zA5f3O5KTTz+aq6wbz5oRXue3mARQVFXH2+RclHS+vPCc2TgCKnAEHbEQDFEJoAmwRY6zIYZ7NWp9vHM9xx58AwFnf6stncz9LOFFy/jh0CIurqnhg2AhKSkro1r0H8xfMZ/CggVxxVX9KSkqSjpg31iIrre+RB158v9bzF6d/zhbNGnFW15244aFJfLFkOa/PmlfrmM677sKKlZHH3/gwn1ET4Xsky1pkWYuMIbfdwgFdDuOGX/4egMOP7sb8ygqG3HYLZ5xzAU2aNk04Yf54TihX6rUKXAiheQjhhhDCNGAx8GmNfV1CCP8MIeyX65Cbi6IiF9VbZfSoJ+je89haH0Z9TzuDqqoq/vPsuAST5Z+1yPI9kjVv0TKaNFp3PY7vtB0vz/icT+YvyWOqZPgeybIWWdYiY8qkNzn0yK/X2nb4UZkm6PXxLyeUKhmeE8qVDf6/kRBCS+A/wPXASmA6te+nNBn4BvB/uQyozdPbU6fQocOetbaVl5dTXFzM1KlTEkqVDGuhVYoCNG9SxEE7l3HOETvxtxdm1XncTlsVs3e7Vjw2YU6eEybD90iWtciyFhlLlyyhSZMmtbY1bdYMgJnTpiYRKTGeExspBEIBP/KpPlPgrgUOAi6OMd4ZQhhIphkCIMb4RQhhHNA9txG1OaqoqKBVq9K1tpeWlTGvIl2zJq2FVvnfz3rSrEkjAEa8OpufP1b3P9jHH7A9S5evZNSbH+czXmJ8j2RZiyxrkbHjzrsy8Y3Xam373+uvAlA57/MkIiXGc0K5Up/5KH2Bf8cY76x+XtcS2e8C7TY2lBqGurr5GGMq16C3FgI47Y4XOf2OF/nZI5Ppvvc2DDxprzqPO67Tdvz37blUVi3Lc8Lk+B7JshZZ1gJOO+u7PD3mXwz/271UzqvguWee4v7qVeCKGjVKOF3+eU4oF+rTAJUD49dzzHxg7dZcqVNWVkZl5by1ts+vrKRVabpOEWuhVSZ+MJ/x71bwp2ffZdDDkzjz8J0ob1Nc65g9t9uS9ttswWMTGv7iB6v4HsmyFlnWIuOk08+h71nncdO1l3PEvuVc3u9MvnfZjwBos1XbhNPll+fExguhcB/5VJ8GaCGwvnv87AJs8Hhs9aIKL4cQ3gghTAwh3FDHMc1CCP8IIUwLIbwUQti5HpmVkD067LnWfNz333+fhQsXrjV/t6GzFqrLxA/mA9CudYta24/rtB1VS1fw1MR0TH8D3yM1WYssa5HRqFEjfnLTrYx7fSYPjnmRZyZMZ/8DugCw34FdEk6XX54TypX6NEDjgd4hhOK6doYQtgZ6Ac/X4zWXAMfEGPcHOgG9QgiHrnHMeUBFjLE98Bvglnq8vhJybK/ePDVmNAsWLFi9bfiwf9CiRQuOPOroBJPln7VQXQ7auQyA2Z9X1drep9N2/HvSJyxamp4b+/keybIWWdaitlalZezRcW+KW27BA/ffTafOh7Br+w5Jx8orzwnlSn0aoDuAbYCHQwjlNXdUP/87sAWwwbcnjhlfVD9tUv1Y89qiE4D7qr8eDnQLBTrRc9GiRTw8YjgPjxjOnDlzmDv309XPFy1alHS8vDq/34U0a9aMM/qezL/HPsU9dw9l8KCBXHLZFalbp99aZKX1PfKn8ztz3tG7cNSeW3HEHltxac/2/Pj4PXlswhxmfZb9e3cqL6W8TTGPpmT1t1V8j2RZiyxrkfHGay/z/4bczgv/eZqnnhjJFReezZOPj+S6n92WdLS885xQrmzwKnAxxkdCCL8CrgJmkpkSRwjhXWBHMkti3xhjrNdC7CGERmRGl9oDv48xvrTGITsA71dnWB5CqATaAAV3e/RPP/mEs//v9FrbVj1/a8p0dtp55wRSJaOsrIzHR4/l8ksv5pQTj6e0tJQfXno51w0YmHS0vLMWWWl9j7z5fiWndNmBHcpasGJl5P3PFvGrx9/m72ssg/2NTtsxv2oZz04puI+3Tcr3SJa1yLIWGY0bN2HUoyO48zc3U1RUxIEHH8b9I55kj457Jx0t7zwnNl6BjiHkXYixrsXcvuQbQjgOuBQ4FGhJZhrbi8CvY4yPfuUgIZQCDwE/jDG+VWP7RODYGOPs6ufTgYNjjJ+t8f39gH4AO+5YftCkd2Z+1SgNSuMvudGi0mv5ipVJRygYnX4yOukIBeOtn/dOOoJU0KZ99MX6D0qJ9ttukXSEgtGiSRgfY+ycdI71abPr3vEbN/096Rjr9Ocz989bHetzHyAAYoyPAY8BhBCaxhiX5iJIjHFeCOEZMtcRvVVj12wyI0yzQwiNgVbUsdBCjHEoMBTgwIM616+rkyRJkpQKGzU8sLHNTwhh6+qRH0IILcjcRHXNOwM+Any7+utTydyLyAZHkiRJ2kABKAqF+8ineo8AhRC2Bb4FHEBmNKYSmAD8Pcb4UT1fbjvgvurrgIqAf8YYHwshDAJejTE+AtwD/DmEMI3MyM8Z9c0sSZIkSVDPBiiE8D3g10BzMo3kKmcCN4UQrogx3rWhrxdjfJNMI7Xm9gE1vl4M9K1PTkmSJEmqywY3QCGEk4A/kFn97dfAM8BHwLbA14HvAXeGED6OMT6c+6iSJEmSvipXgcuozwjQj4D5QJcY4ztr7PtXCOFu4OXq42yAJEmSJBWc+iyCsC+Za3TWbH4AiDFOBf4J7JeLYJIkSZKUa/UZAVrI+m8+OhdwkXxJkiSpwDgBLqM+I0BjgW7rOaYb8NRXjyNJkiRJm059GqD+QLsQwt0hhLY1d4QQ2oYQ/ghsD1yTy4CSJEmSlCvrnAIXQnikjs2zge8CZ4UQpgIfA9sAHYCmwKvAHcAJuY8qSZIk6asIAYpcBQ748muAjvuSfc2oe7GDLkDcqESSJEmStIl8WQO0Zd5SSJIkSVIerLMBijEuzGcQSZIkSZuOM+Ay6rMIgiRJkiRt1upzH6DVQghlZFZ8a1bX/hjjaxsTSpIkSZI2hXo1QCGEI4Bbgc7rObTRV04kSZIkSZvIBjdAIYQDyNzkdAHw/4BzgReAmcDhwM7A48DkXIeUJEmStHGCFwEB9bsG6CfACuDgGON51dtGxxjPAvYAfg10BYbmNqIkSZIk5UZ9GqAjgEdijDNrbAsAMcblwNXAe8CNuYsnSZIkSblTn2uAyshMd1tlGdBy1ZMYYwwhjAPOyFE2SZIkSTniDLiM+owAzQVa1Xj+CbBLHa/XEkmSJEkqQPVpgN4Bdq3x/BWgRwhhJ4AQQhvgZGB67uJJkiRJUu7UZwrcKOCnIYRWMcZK4HfACcDrIYTXgb2BNsDAnKeUJEmS9JUFAkXOgQPqNwI0FDiO7MIHTwPfBiqBo4ElwNUxxrtzHVKSJEmScmGDR4BijJ8DY9fY9hfgLyGERjHGFbkOJ0mSJEm5VJ8pcOtk8yNJkiQVsOAqcKvUZwqcJEmSJG3W1jkCFEJ48yu+Zowx7v8Vv1eSJEmSNpkvmwK3PRDzFUSSJEnSphOcAwd8SQMUY9wqn0EkSZIkaVPzGiBJkiRJqZGTVeAKTQAaN7K3k9bF90fWw5cdmXSEgtH15qeTjlAw/nVJ16QjFIzSlk2TjlAw2m+7RdIRJOVAg2yAJEmSJNXmrz8zrIMkSZKk1LABkiRJkpQaToGTJEmSGriAy2Cv4giQJEmSpNSwAZIkSZKUGvWeAhdCaA+cAXQEWsYYT6ze3g7YD/hvjHF+TlNKkiRJ2ihFzoAD6tkAhRD6AzfV+L5YY3cL4FHgYuAPOUknSZIkSTm0wVPgQggnAT8HngeOAG6tuT/G+A4wATghlwElSZIkKVfqMwJ0OfAu0CvGuDiE0KOOYyYCR+UimCRJkqTccQpcRn0WQegEPBFjXPwlx8wBttm4SJIkSZK0adSnAWoELF3PMVttwDGSJEmSlIj6TIGbDhy6rp0hc2elw4HJGxtKkiRJUu6E4I1QV6nPCNBw4OAQwoXr2H8ZsCfwj41OJUmSJEmbQH1GgG4FTgd+H0LoCzQBCCEMBI4Evga8DtyZ24iSJEmSlBsb3ADFGBeGEI4GhgAnAavG0AZU//kQcEGM0WuAJEmSJBWket0INcY4Fzg1hLADmeuB2gCVwIsxxvc2QT5JkiRJOeAy2Bn1aoBWiTF+ADyY4yySJEmStEnVZxEESZIkSdqsbfAIUAjhtxt4aIwxXvoV80iSJEnaBFwFO6M+U+AuXs/+SGZhhAjYAEmSJEkqOPWZArfvOh5HAlcAn5K5B9B+Oc64WZk8aRK9e3ajdUkxu5Rvz6CBA1ixYkXSsRJhLbKsRZa1yBo76lFO7nEoB+7Whl6H78N9Q3+XdKRNrlvHrfnTdw5k7JVH8PyPj+LBHxzCeUfsRON1XJl7Zc/2jL/+6/x/9u47zo6yevz452yy6Wx2E2ogIdQQkB6QZgBDC0UQBYJfECkCSi/GhhgD/FBsiH4Vo4IgfkVDEVR6QIqINFFpAYKEhIQS2PSePL8/5iaTTYEAmzubO5+3r32xd+7s3ZPjM7P3zHPmuWfvs0mVIy3exAmvscn6PVivsSMzpk8vOpxCeL7ImIecuVBreD/LYD/zLk//LSJuBf4F/Bl4t31rVnNzMwcesA/9+2/JyJtu4eUxY/jK0PNYuHAhw4ZfXHR4VWUucuYiZy5y/3zs75xz8v/wyaOO5fwLLuHf/3ycyy+9kLq6Oo496bSiw1tluneu5/Gxzfzm768ybfZ8tlq/gZMH9qVntw5cdseLLfbdaM0ufGK79Zg+e35B0Rbrogu/Steu3Zg5Y0bRoRTC80XGPOTMxYcTQJ09cMAHXAVueVJKL0fELcB5wG9b63VXJ78ccSWzZ83i+pE30dDQwKB99mXqtKlcMnwY554/lIaGhqJDrBpzkTMXOXORu/Ly77D9Trvyre/+LwC77TmIqVOaufLy7zDks5+nvkOHgiNcNW56ckKLx4+PnUzXju04csD6yxRAX9p/M65/dDwHbr1ONUNsEx55+CHuu+cuzjxvKMO/8dWiwymE54uMeciZC7WW1l4FbiKwRSu/5mrjzjtuZ5/99m9xAB5x5BBmzZrFgw/cX2Bk1WcucuYiZy5yzz/7b3b52N4ttu02MCuCnnri0YKiKsaUmfOpb9fyz9Gg/mux0Zpdufpv5fuIuQULFnDB0HM4Z+jX6NFjzaLDKYzni4x5yJkLtZZWK4AiIoCBQDkblYEXRj9Pv34t678+ffrQpUsXRo9+vqCoimEucuYiZy5yc+fMob6+vsW2Dh07AvDfl0YXEVJV1QV0al/Hdr27M2Tn9bnh8dcWP9exfR3n7LMpP753DLPnLSwwymJce9UIZs+ZzfGf/0LRoRTK80XGPOTMxYdX14a/qun9LIO9w7u8Rm/gRGAAcE0rxLVaam5upnv3xmW2NzY1Mbm5uYCIimMucuYiZy5yvftuzDP/erLFtv889TgAUya/U0RIVfXQVwbSsX07AP78r4lcfs+Yxc8dv/uGTJo+h9v+80ZR4RXmnXfe5rJLvsVPRly9TIFcNp4vMuYhZy7UWt7PPUCPky1xvSJR2edLHyqi1Vws5+aylNJyt9c6c5EzFzlzkTnymBO4+GvncMP/Xc2+Bx7G0089wbWVVeDq2rUrOLpV74Srn6RTfTu26tXA5wduyJcHb863b3+BXo2dOHbX3pzym6eKDrEQ377oQrYfsBOD9htcdChtgueLjHnImWXbcp0AACAASURBVAu1hvdTAP2A5RdAC4Fm4FHgvpTSuxVJNa2pqYkpUyYvs33qlCl0b1z2ikUtMxc5c5EzF7lPHvVZRj/7NBd/7Ry+9eUz6dy5C2d/bTiXfuN8eq65dtHhrXLPv551Sz81bgqTZ81l+KFbct0jr3La3hvzt5fe5pVJM+nWMfsTVRdBfbs6unVsz/Q5tbsi3OjnnuX6667h5ttGMWVydpzMmjUTgKlTp1DXrh2dO3cuMsSq8nyRMQ85c/HhWSdm3s8y2Oe39i+PiH5knx20yMbAhSmly5fYJ4AfAQcCM4HPpZRa9o20EZv322KZHtRx48YxY8aMZXpWa525yJmLnLnItWvXjq9f/H1OP/8C3pg4gQ36bMh/X3oBgG122Kng6Krr+YlZMdSrsTMb9uxCv3XXYFD/lkXgkJ03YMjOGzD48od5c9qcIsJc5V4e8yLz5s3j4H0HLvPcDltuzGeOPZ7v//jKAiIrhueLjHnImQu1lvdzD9AVwHMppZ+11i9PKY0Gtqu8fjvgNeDmpXYbDGxW+foo8LPKf9uc/Q8YzA+//12mTZvGGmusAcANI39P586d+djAPQuOrrrMRc5c5MzFsro3NtG9sQmA66/9BdsN+Cgbb9qv4Kiqa9ve3QGYMHkWF/15NF06tGwB/H+Hb8mTYydzwxMTaJ45t4gQq2LnXXfnxj/d1WLbfaPu4ieXf4/rRt7Chn03KiiyYni+yJiHnLlQa3k/LXCnAD9cVYEAg4AxKaWl1zw9FLi20lr3SEQ0RsR6KaWJqzCWD+Skk0/lpz+5giFHHM55X/oy/335ZS4ZPowzzz63dGvTm4ucuciZi9y/nnyUfz76d/pttQ0zpk/ltltu4OH7R3HNTXe99w+vxn589DY8+t9mxrw1g4UpsW3v7hyzS2/ufOYNxjfPBmYv8zNz5y/kjalzeGLssq0vtaRnzzXZ7WMt38SNezX7k7jLrnvQtVu3IsIqjOeLjHnImYsPJyL8INSK91MAvQr0XFWBAEOA3y1n+/rAuCUej69sa3MFUFNTE7fdOYpzzjqdTx12CI2NjZxx1jlccOGwokOrOnORMxc5c5Fr376eO/50Ez/94aXU1dWxw867cu1Nd7N5/62KDm2VenbiNA7edl16NXZiwcLEa82z+cm9L3PjExPe+4dVKp4vMuYhZy7UWmJl1yyIiIuBzwJbpZSmtWoQER2ACZXXfmOp5/4CXJpSeqjyeBQwNKX0xFL7nQycDNC7T58dXxhTvg/Pk/T+vfR6aT+6bBnHXf1Y0SG0GX85c/eiQ2gzGrt2KDoEqU3rXB9PpJQGFB3He+m1+dbpxCtuKjqMFbp48OZVy+P7+dyhi4EXgLsjYq+I6NqKcQwGnly6+KkYT/Y5Q4tsQFYstZBSGpFSGpBSGrDWmmu1YmiSJEmSasX7aYF7k6xg6gKMAoiImSy7NHZKKXV/n3EczfLb3wBuBU6PiOvJFj+Y0hbv/5EkSZLaMm8ByryfAugF3v2DUD+QiOgC7Eu2yMKibacCpJSuBG4jWwL7JbJlsI9v7RgkSZIklcP7+RygVdKTl1KayVKLK1QKn0XfJ+C0VfG7JUmSJJXLuxZAEfFZ4KmU0r+rFI8kSZKkVaDOFjjgvRdB+DVwWBXikCRJkqRV7v2sAidJkiRJq7X3swiCJEmSpNVQAHUuAwc4AyRJkiSpRFZmBqgxIvq8nxdNKb36AeORJEmSpFVmZQqgsypfKyut5OtKkiRJqhI74DIrU6hMBSav6kAkSZIkaVVbmQLohyml4as8EkmSJElaxWxVkyRJkmpd+EGoi7gKnCRJkqTSsACSJEmSVBoWQJIkSZJK413vAUopWSBJkiRJNSDwJiBwBkiSJElSiVgASZIkSSoNl8GWJEmSalzgMtiLOAMkSZIkqTQsgCRJkiSVhi1wkiRJUgnYApdxBkiSJElSaVgASZIkSSoNW+AkSZKkEoiwBw6cAZIkSZJUIhZAkiRJkkrDFjhJkiSpxvlBqDlngCRJkiSVhgWQJEmSpNKoyRa4+QsTk2fMLTqMNqGxa4eiQ5DatDXX8BhZ5MYv7Fp0CG3Gib97qugQ2owbT9q56BDajPkLFhYdQpvRvp3X0Fc7AS4Cl3H0SpIkSSoNCyBJkiRJpWEBJEmSJKk0avIeIEmSJEkt1XkTEOAMkCRJkqQSsQCSJEmSVBq2wEmSJEk1LoA6O+AAZ4AkSZIklYgFkCRJkqTSsAVOkiRJKgEXgcs4AyRJkiSpTYuI3hFxX0Q8FxHPRMRZle09IuLuiHix8t+m93otCyBJkiRJbd184LyUUn9gF+C0iNgS+AowKqW0GTCq8vhd2QInSZIk1bygjtW3By6lNBGYWPl+WkQ8B6wPHArsVdntGuCvwJff7bWcAZIkSZK02oiIvsD2wD+AdSrF0aIiae33+nlngCRJkiQVbc2IeHyJxyNSSiOW3ikiugE3AmenlKbGB1jZwQJIkiRJqnFBm18FblJKacC77RAR9WTFz29TSjdVNr8REeullCZGxHrAm+/1i2yBkyRJktSmRTbV8yvguZTSD5Z46lbguMr3xwG3vNdrOQMkSZIkqa3bHTgW+E9EPFXZ9jXg28AfIuJE4FXgiPd6IQsgSZIkSW1aSukhWOEydoPez2tZAEmSJEm1LqCubd8DVDXeAyRJkiSpNCyAVpGJE15jk/V7sF5jR2ZMn150OIV47tlnGbzfIHo0dGGjPr0YPuxCFixYUHRYhTAXOXOxLM8XMH/+fH72o++y984fod/63dl1m0246IIvFR3WKrX7xk1877D+/O5zO3DzSQP4+ZCtOWqHXrRf6hLtkduvx6+P2ZabThrAdz6xBRv37FJQxNXn+SIzZsxLnHnaqey60/Z071LP4H0/XnRIhXFMqDXYAreKXHThV+natRszZ8woOpRCNDc3c+AB+9C//5aMvOkWXh4zhq8MPY+FCxcybPjFRYdXVeYiZy6Wr+znC4AvnXkyDz9wH2d96etsvGk/Jk4Yz0ujnys6rFVqjY7t+feEadz41OvMmDufzdfuxmcGrE9Tl3qufGgsAEdsvx5Ddlyfq/7+KuMnz+awbdfl4oP7cdofnqZ51ryC/wWrlueL3HPPPsNdd9zOTh/9KHPnzi06nMI4Jj68uja+Dna1WACtAo88/BD33XMXZ543lOHf+GrR4RTilyOuZPasWVw/8iYaGhoYtM++TJ02lUuGD+Pc84fS0NBQdIhVYy5y5mJZni/g/lF38eebR3LbXx9ls379iw6nau547q0Wj/89YRpdOrTjoK3W5sqHxlLfLjhiu/UY+c8J/PmZ7GMtnntjOlf/z7Yc/JG1+c1jrxURdtV4vsgdeNAhHHzIoQAcc/QRvD3p7YIjKoZjQq3FFrhWtmDBAi4Yeg7nDP0aPXqsWXQ4hbnzjtvZZ7/9W5yMjjhyCLNmzeLBB+4vMLLqMxc5c9GS54vMH/7vGnbdY69SFT8rMnX2/MUtcP3X6UbXju15cMw7i5+fM38h/xg7mQF9GosKsWo8X+Tq6ny7Bo4JtR6PqFZ27VUjmD1nNsd//gtFh1KoF0Y/T79+W7TY1qdPH7p06cLo0c8XFFUxzEXOXLTk+SLz1JOPsdEmm3Lhl89m643Wpn+fHpz6uaN44/UJRYdWFXUBHdvXseW63fjE1utw27PZbE/vps4sWJiYMGV2i/3HNc9ig8ZORYRaVZ4vtDTHxIcTQETb/aomW+Ba0TvvvM1ll3yLn4y4mvr6+qLDKVRzczPduy97hbKxqYnJzc0FRFQcc5EzFznPF7lJb77BjddfR/+ttuaKEdcyY/o0Lh3+dU457ihuvuMBosZ71m88cQAd2mfXI+8ZPYmr/j4OgG4d2zFr3gIWppb7T5+zgE717WhfF8xf+ska4vlCS3NMqLVYALWib190IdsP2IlB+w0uOpQ2YXlvWlJKNf9mZnnMRc5cZDxf5FJKpJQY8ZuRNPXoCcBa66zHkEP35eEH/8ruA/cuOMJV6/w/PkvH9nVsvnY3jt6xF1/42Ib89MGxK9x/0aFSu6VPzvOFluaYUGuwAGolo597luuvu4abbxvFlMmTAZg1ayYAU6dOoa5dOzp37lxkiFXV1NTElCmTl9k+dcoUujfWfu/6ksxFzlxkPF+01NDYRJ8N+y4ufgB22mU3OnTowIujn6v5AmjMpOz/+2dfn87U2fM47+ObcNO/Xmf6nAV0rm9HXdBiFqhrh3bMnreABTU8+wOeL7Qsx8SH5ypwmcILoIhoBH4JfITsgtYJKaW/L/F8AD8CDgRmAp9LKT1ZRKzv5uUxLzJv3jwO3nfgMs/tsOXGfObY4/n+j68sILJibN5vi2X6cceNG8eMGTOW6d+tdeYiZy4yni9a2nSzfsydO2eZ7Sml0t38PeatrBhad42OjGueRbu6YL2GTry2xH1AvRs7M37y7BW9RM3wfKGlOSbUWgovgMiKmztSSp+OiA7A0p/wNhjYrPL1UeBnlf+2KTvvujs3/umuFtvuG3UXP7n8e1w38hY27LtRQZEVY/8DBvPD73+XadOmscYaawBww8jf07lzZz42cM+Co6suc5EzFxnPFy19fL/BXH7Zxbzz9iR69MxWw3v07w8xb948+m+1dcHRVVf/dbsB8Pq0Obw9Yy4z5sxnj0168PsnswUhOravY+e+jdxRWSihlnm+0NIcE2othRZAEdEADAQ+B5BSmgss/QlfhwLXppQS8EhENEbEeimliVUN9j307Lkmu32s5cE37tWsh3uXXfega7duRYRVmJNOPpWf/uQKhhxxOOd96cv89+WXuWT4MM48+9zSrdNvLnLmIuP5oqWjP3si1/zip5x0zKf44tlDmTF9Gt8ZfgG77/lxdtpl96LDW2WGH7g5T702lbHvzGJhSmy57hp8ctt1uf+lt3l9ajYjNvKpiQzZoRfT58xn/OTZfHKbdQngT0+/UWzwVeD5Ijdz5kzuuuM2ACZMmMC0qVP54003ALDfAQfSpcvS145rk2Piw7MDLlP0DNDGwFvA1RGxLfAEcFZKacmPQ18fGLfE4/GVbW2qAFJLTU1N3HbnKM4563Q+ddghNDY2csZZ53DBhcOKDq3qzEXOXGh51lijgd/edAff+tp5nHnyZ6mv78C+BxzMNy6+rOjQVqkX3prBoH5rss4aHVmwMPH61Dlc84/xi5fBBhj5z4nUBRy5fS/W6NSeF9+awQV/Hs3kWfMLjLw6PF/k3nrzTY79zFEtti16/PTzY9iwb98Coqo+x4RaS2QTKwX98ogBwCPA7imlf0TEj4CpKaVvLLHPX4BLU0oPVR6PAoamlJ5Y6rVOBk4GWL93nx0f/8+L1fpntGmNXTsUHYLUpk2esfSkc3nNnrew6BDajNNu+HfRIbQZN560c9EhtBnzF3iMLNK+Xbnuz3s3nevjiZTSgKLjeC99+2+TLrz2z0WHsUIn7rxh1fJY9OgdD4xPKf2j8vgGYIfl7NN7iccbAMt8Ol5KaURKaUBKaUDPnuX9RHVJkiRJK1ZoAZRSeh0YFxH9KpsGAc8utdutwGcjswswpa3d/yNJkiS1ZUH2xr+tflVT0fcAAZwB/LayAtzLwPERcSpASulK4DayJbBfIlsG+/iiApUkSZK0eiu8AEopPQUs3e935RLPJ+C0qgYlSZIkqSYVXgBJkiRJWsUCwnWwgeIXQZAkSZKkqrEAkiRJklQatsBJkiRJJWADXMYZIEmSJEmlYQEkSZIkqTRsgZMkSZJqXAB1rgIHOAMkSZIkqUQsgCRJkiSVhi1wkiRJUgnYAJdxBkiSJElSaVgASZIkSSoNW+AkSZKkEnARuIwzQJIkSZJKwwJIkiRJUmlYAEmSJEkqDe8BkiRJkmpeEN4EBDgDJEmSJKlELIAkSZIklYYtcJIkSVKNC5z5WMQ8SJIkSSoNCyBJkiRJpWELnCRJklQCrgKXcQZIkiRJUmlYAEmSJEkqDVvgJEmSpBKwAS7jDJAkSZKk0rAAkiRJklQaNdkC174uaOzaoegwpDZr/oKFRYfQZrRv53WgRdb1vLnYjSftXHQIbcYmZ95cdAhtxpgrPll0CNIHF64Ct4h/+SVJkiSVhgWQJEmSpNKwAJIkSZJUGjV5D5AkSZKkXODMxyLmQZIkSVJpWABJkiRJKg1b4CRJkqQScBnsjDNAkiRJkkrDAkiSJElSadgCJ0mSJJWADXAZZ4AkSZIklYYFkCRJkqTSsAVOkiRJKgEXgcs4AyRJkiSpNCyAJEmSJJWGLXCSJElSjQugznXgAGeAJEmSJJWIBZAkSZKk0rAFTpIkSSoBV4HLOAMkSZIkqTQsgCRJkiSVhgVQK3vu2WcZvN8gejR0YaM+vRg+7EIWLFhQdFiFMBc5c5EZM+YlzjztVHbdaXu6d6ln8L4fLzqkwtz6xxs5cNDH2LzPOmywZjd22X4rvn/Z/2Pu3LlFh1YIj5FcGXNx0Pa9uOX8gTx92UGM+dEneOCb+3DWAf2ob5f36zR0ruf7x+zA0989iBd+cAi/OW1X+q7VtcCoq6eMY2JFzIVag/cAtaLm5mYOPGAf+vffkpE33cLLY8bwlaHnsXDhQoYNv7jo8KrKXOTMRe65Z5/hrjtuZ6ePfrS0b/QXaX7nbXYfuBennXUe3RsbefLxx/jupcN5843X+c73ryg6vKryGMmVNRdNXTvw8AuT+NndLzJ11jy227CJcw/qz1oNHbngD/8G4Gcn7kS/Xg18c+S/mTprHmcN7sfvz9yDQZeMYvrs+QX/C1adso6J5TEXH1YQLoMNWAC1ql+OuJLZs2Zx/cibaGhoYNA++zJ12lQuGT6Mc88fSkNDQ9EhVo25yJmL3IEHHcLBhxwKwDFHH8Hbk94uOKLiHHfCyS0e7zFwL6ZNm8pVv/gZ3/7ej4gS3anqMZIray6ue+iVFo8ffmESa3Su57iBG3HBH/7Njhv1YK8t1+HIyx/kby9MAuCfrzTzyEX78T979OXn97xUQNTVUdYxsTzmQq3FFrhWdOcdt7PPfvu3OACPOHIIs2bN4sEH7i8wsuozFzlzkaur85Tzbnr06MG8Es6MeYzkzEWuefpcOrTPzhlbbdCdeQsW8vcXJy1+ftK0OTz32lT2+ci6RYVYFY6JnLlQa/HdSCt6YfTz9Ou3RYttffr0oUuXLowe/XxBURXDXOTMhd7NggULmDlzJo88/BC/uPJ/+dyJp5Rq9gc8RpZU9lzUBXSqb8dOm/TkhL035toH/gtAx/o65i9ILEwt958zfyGbrrNGAZFWT9nHxJLMxYcX0Xa/qskWuFbU3NxM9+6Ny2xvbGpicnNzAREVx1zkzIXezYbrdGfOnDkAHHn0MQy75DsFR1R9HiO5sufixcs/Qaf6dgCMfORVLrr5aQBeeWsGnTu0Y4teDTw/YSoAnerr2GK9Brp2qu23MmUfE0syF2otzgC1suVduU0ple6KLpiLJZkLrchf7nmAP915H8P/32Xccduf+Mp5ZxYdUiE8RnJlzsWh37ufw77/AN+64T/st826XHLUtgD89dk3GDtpBt/5zHZssnY31m7oyLeP3p41OrdnwdLTQjWozGNiaeZCraG2L5tUWVNTE1OmTF5m+9QpU+jeuOwVi1pmLnLmQu9m2+12AGCX3fagR881Of2UE/jCGeew0cabFBxZ9XiM5Mqei6fHTQHgsTFv886MOfzouAH8/J6XGDtpBl/81WP87wkDeGDYvgD846VJ3PCPcezeb80iQ17lyj4mlmQuPpwA6lwFDii4AIqIq4CDgTdTSh9ZzvMB/Ag4EJgJfC6l9GR1o1x5m/fbYpke1HHjxjFjxoxlelZrnbnImQutrG222x6AV8e+UqoCyGMkZy5y/3k1e6Pbp2cXxk6awVNjm9n9m3ezydrdmL8wMXbSDK75wq48+d/abn1yTOTMhVpL0S1wvwYOeJfnBwObVb5OBn5WhZg+sP0PGMw9d93JtGnTFm+7YeTv6dy5Mx8buGeBkVWfuciZC62sRx95GIA+G/YtNpAq8xjJmYvcTpv0BODVt2e22D7mzemMnTSDjdbqyh5brMXvHn6lgOiqxzGRMxdqLYUWQCmlB4B33mWXQ4FrU+YRoDEi1qtOdO/fSSefSseOHRlyxOHcO+oefvWLEVwyfBhnnn1u6damNxc5c5GbOXMmf7zpBv540w1MmDCBSZPeWvx45syZ7/0CNeTITx7E//7oB9xz1x3cN+puvnPJt7jwa0M57FNHlmr2BzxGllTWXFx32m6css+m7L3lOgzsvzbnHbQFFx6+Nbc8Pp6xk2YAcPbgfhy8fS9223xNTthrY245f09ufXw8Dz7/VsHRr1plHRPLYy4+pDaw0purwK2c9YFxSzweX9k2sZhw3l1TUxO33TmKc846nU8ddgiNjY2ccdY5XHDhsKJDqzpzkTMXubfefJNjP3NUi22LHj/9/Bg27Nu3gKiKsf0OA7j+t9fy6quv0L59ezbsuxEXDLuYz514StGhVZ3HSK6sufjX2GaO3GVDevfowvyFC3l10kwuvfUZflNZBhugqWsHhh2xDT26dmBC8yyuvOdFfj6qdj8AdZGyjonlMRdqLZFSsaunRERf4M8ruAfoL8ClKaWHKo9HAUNTSk8sZ9+Tydrk6N2nz44vjBm7KsOWVmvzFywsOoQ2Y/Y8c7FItxpfTlgfzCZn3lx0CG3GmCs+WXQIaoM618cTKaUBRcfxXjb/yHbpx3+4u+gwVuiArdauWh6LvgfovYwHei/xeANgwvJ2TCmNSCkNSCkNWGvNtaoSnCRJkrS6KLrNra20wLX1AuhW4LOR2QWYklJqk+1vkiRJktq+opfB/h2wF7BmRIwHvgnUA6SUrgRuI1sC+yWyZbCPLyZSSZIkSbWg0AIopXT0ezyfgNOqFI4kSZKkGucdr5IkSVIJBFW+2aaNauv3AEmSJElSq7EAkiRJklQatsBJkiRJNS6AOjvgAGeAJEmSJJWIBZAkSZKk0rAFTpIkSSoBV4HLOAMkSZIkqTQsgCRJkiSVhi1wkiRJUgmEHXCAM0CSJEmSSsQCSJIkSVJp2AInSZIklYCrwGWcAZIkSZJUGhZAkiRJkkrDAkiSJElSaXgPkCRJklTjAqjzFiDAGSBJkiRJJWIBJEmSJKk0bIGTJEmSal64DHaFM0CSJEmSSsMCSJIkSVJp2AInSZIk1bqAsAMOcAZIkiRJUolYAEmSJEkqDVvgJEmSpBKwAy7jDJAkSZKk0rAAkiRJklQatsBJJdS+ndc+Fpk+bW7RIbQZ3Tr5J2GRyTMcF4uMueKTRYfQZnz8Bw8UHUKbce+5A4sOQe9TAHUuAwc4AyRJkiSpRCyAJEmSJJWG/Q6SJElSCdgAl3EGSJIkSVJpWABJkiRJKg0LIEmSJEml4T1AkiRJUhl4ExDgDJAkSZKkErEAkiRJklQatsBJkiRJJRD2wAHOAEmSJEkqEQsgSZIkSaVhC5wkSZJUAmEHHOAMkCRJkqQSsQCSJEmSVBq2wEmSJEklYAdcxhkgSZIkSaVhASRJkiSpNGyBkyRJksrAHjjAGSBJkiRJJWIBJEmSJKk0LIBa2XPPPsvg/QbRo6ELG/XpxfBhF7JgwYKiwyqEuciZi5y5yM2fP5+f/ei77L3zR+i3fnd23WYTLrrgS0WHVQjHxbImTniNTdbvwXqNHZkxfXrR4RSijONi783X5Of/sy23n7Er9527B787aQCf27UP7euy3qX2dcFFn+jPyJN34r5zducvp+/C9z/9Efqt063gyKujjGNCrc97gFpRc3MzBx6wD/37b8nIm27h5TFj+MrQ81i4cCHDhl9cdHhVZS5y5iJnLlr60pkn8/AD93HWl77Oxpv2Y+KE8bw0+rmiw6o6x8XyXXThV+natRszZ8woOpRClHVcNHSu58lXp/DbR8czfc58tlx3DU7cfUN6dK3nB/eMoa4uSCR+88g4Xps8m64d2nHUTuvz4yHb8LlfP8mEKbOL/iesMmUdE60lgPAmIMACqFX9csSVzJ41i+tH3kRDQwOD9tmXqdOmcsnwYZx7/lAaGhqKDrFqzEXOXOTMRe7+UXfx55tHcttfH2Wzfv2LDqdQjotlPfLwQ9x3z12ced5Qhn/jq0WHU4iyjotb/jWxxeMnX51C147tOXz7XvzgnjHMnb+QC299vsU+j41t5vYzdmPgZj25/vHXqhluVZV1TKj12QLXiu6843b22W//FgfgEUcOYdasWTz4wP0FRlZ95iJnLnLmIveH/7uGXffYq/TFDzgulrZgwQIuGHoO5wz9Gj16rFl0OIVxXOSmzJpHfbsVX7mfNW8hcxcspL5dbb+tc0yotdT2kVJlL4x+nn79tmixrU+fPnTp0oXRo59fwU/VJnORMxc5c5F76snH2GiTTbnwy2ez9UZr079PD0793FG88fqEokOrOsdFS9deNYLZc2Zz/Oe/UHQohSr7uKgL6Ni+jm3Wb+CIHdfn5qcmLrNPu4AeXes5ba+NWLgwcfdzbxYQafWUfUx8aAHRhr+qyRa4VtTc3Ez37o3LbG9samJyc3MBERXHXOTMRc5c5Ca9+QY3Xn8d/bfamitGXMuM6dO4dPjXOeW4o7j5jgeIav81KJDjIvfOO29z2SXf4icjrqa+vr7ocApV9nEx6pw96Ng+u05929Nv8JP7Xm7x/LEf7c0X9twIgOYZcznvhqd5feqcqsdZTWUfE2o9FkCtbHlvWlJKpXozs4i5yJmLnLnIpJRIKTHiNyNp6tETgLXWWY8hh+7Lww/+ld0H7l1whNXluMh8+6IL2X7ATgzab3DRobQJZR4Xp/z2KTq1r2PL9dbg+N025Lx9N+V7d7+0+Pm/PP06j41tpmfXDhy+fS+++6mP8MXf/YtX3p5ZYNSrXpnHhFqPLXCtqKmpiSlTJi+zfeqUKXRvXPaKRS0zFzlzkTMXEPWlWAAAIABJREFUuYbGJvptudXi4gdgp112o0OHDrxYspXgHBeZ0c89y/XXXcN5X76AKZMnM2XyZGbNyt7MTp06hVmzZhUcYXWVfVy88MZ0/v3aVK5//DV+OOolDt++F+s3dlr8/Dsz5vH869P525h3GHrj00yZPY9jP9q7wIhXvbKPidYQbfirmtrEDFBEtAMeB15LKR281HMdgWuBHYG3gaNSSq9UPciVsHm/LZbpQR03bhwzZsxYpme11pmLnLnImYvcppv1Y+7cZdtVUkrU1ZXr2pTjIvPymBeZN28eB+87cJnndthyYz5z7PF8/8dXFhBZMRwXuRfeyD4Har3unXht8rLLXC9I8PJbM+i1RIFUixwTai1t5a/sWcCKLnmeCDSnlDYFfgh8p2pRvU/7HzCYe+66k2nTpi3edsPI39O5c2c+NnDPAiOrPnORMxc5c5H7+H6Def7Zp3nn7UmLtz3694eYN28e/bfausDIqs9xkdl519258U93tfg6/ezzAbhu5C184cxzCo6wuhwXua3X7w7AxBV8xk+HdsHm63Rb4fO1wjGh1lJ4ARQRGwAHAb9cwS6HAtdUvr8BGBRttNHzpJNPpWPHjgw54nDuHXUPv/rFCC4ZPowzzz63dGvTm4ucuciZi9zRnz2RpqYenHTMp7jnzr9wy43Xc+4XT2D3PT/OTrvsXnR4VeW4yPTsuSa7fWzPFl+bbtYPgF123WPx92VR1nHxg09/hKN32oBdNmpi575NnLj7hpyx98bc89ybvDZ5Nvv2X4tvHNiPffuvxfa9u7Nv/7W4/MhtWLNrB65/bHzR4a9SZR0TraroPrc20gPXFlrgLgeGAmus4Pn1gXEAKaX5ETEF6AlMWnKniDgZOBmgd58+qyzYd9PU1MRtd47inLNO51OHHUJjYyNnnHUOF1w4rJB4imQucuYiZy5ya6zRwG9vuoNvfe08zjz5s9TXd2DfAw7mGxdfVnRoVee40PKUdVw89/o0DvrIOqzbvRMLFiYmTJnFlQ/8d/Ey2GPfmcX+W7bnzL03YY1O7Xl7xlyemTiVE659kf/W+AIIZR0Tan2RUirul0ccDByYUvpiROwFnL+ce4CeAfZPKY2vPB4D7JxSentFr7vjjgPS3/7x+CqMXFKteH05/fRltW6N3z/wfkyeMbfoENqMxq4dig6hzfj4Dx4oOoQ2495zl71Xraw618cTKaUBRcfxXrbcZvt03Z/uLzqMFdqxb/eq5bHoGaDdgU9ExIFAJ6AhIq5LKR2zxD7jgd7A+IhoD3QH3ql+qJIkSdLqKoiqr7fWNhV6D1BK6asppQ1SSn2BIcC9SxU/ALcCx1W+/3Rln+KmrSRJkiSttoqeAVquiBgOPJ5SuhX4FfCbiHiJbOZnSKHBSZIkSVpttZkCKKX0V+Cvle8vXGL7bOCIYqKSJEmSakPbXEe5+gpfBluSJEmSqsUCSJIkSVJpWABJkiRJatMi4qqIeDMinl5iW4+IuDsiXqz8t2llXssCSJIkSapx0ca/VsKvgQOW2vYVYFRKaTNgVOXxe7IAkiRJktSmpZQeYNnPAj0UuKby/TXAYSvzWm1mFThJkiRJpbVmRDy+xOMRKaUR7/Ez66SUJgKklCZGxNor84ssgCRJkqQyaNvLYE9KKQ2oxi+yBU6SJEnS6uiNiFgPoPLfN1fmhyyAJEmSJK2ObgWOq3x/HHDLyvyQLXCSJElSCUQb74F7NxHxO2AvsnuFxgPfBL4N/CEiTgReBY5YmdeyAJIkSZLUpqWUjl7BU4Pe72vZAidJkiSpNJwBkiRJkkogVt8OuFblDJAkSZKk0rAAkiRJklQatsBJkiRJJWAHXMYZIEmSJEmlYQEkSZIkqTQsgCRJkiSVhvcASZIkSbUu8CagCmeAJEmSJJWGBZAkSZKk0rAFTpIkSSqBsAcOcAZIkiRJUolYAEmSJEkqDVvgJEmSpBoXQNgBBzgDJEmSJKlELIAkSZIklYYtcJJKbd3GTkWHoDaosWuHokNQG3TvuQOLDqHN2P3S+4oOQR+AHXAZZ4AkSZIklYYFkCRJkqTSsAVOkiRJKgN74ABngCRJkiSViAWQJEmSpNKwAJIkSZJUGt4DJEmSJJVAeBMQ4AyQJEmSpBKxAJIkSZJUGrbASZIkSSUQdsABzgBJkiRJKhELIEmSJEmlYQucJEmSVAJ2wGWcAZIkSZJUGhZAkiRJkkrDFjhJkiSpDOyBA5wBkiRJklQiFkCSJEmSSsMWOEmSJKnGBRD2wAHOAEmSJEkqEQsgSZIkSaVhAdTKnnv2WQbvN4geDV3YqE8vhg+7kAULFhQdViHMRc5c5MxFzlzkzEXOXOTMRaaseRjUfy2u+twOjDpvDx7+6kBu/OJHOXGPDWlft/w2rvP225QnvrE3Z++zSZUjXU0ERBv+qibvAWpFzc3NHHjAPvTvvyUjb7qFl8eM4StDz2PhwoUMG35x0eFVlbnImYucuciZi5y5yJmLnLnIlDkP3TvX8/jYZn7z91eZNns+W63fwMkD+9KzWwcuu+PFFvtutGYXPrHdekyfPb+gaLU6sQBqRb8ccSWzZ83i+pE30dDQwKB99mXqtKlcMnwY554/lIaGhqJDrBpzkTMXOXORMxc5c5EzFzlzkSlzHm56ckKLx4+PnUzXju04csD6yxRAX9p/M65/dDwHbr1ONUPUasoWuFZ05x23s89++7c4GR1x5BBmzZrFgw/cX2Bk1WcucuYiZy5y5iJnLnLmImcuMuahpSkz51PfruXb10H912KjNbty9d/GFhSVVjcWQK3ohdHP06/fFi229enThy5dujB69PMFRVUMc5EzFzlzkTMXOXORMxc5c5ExD1AX0Kl9Hdv17s6QndfnhsdfW/xcx/Z1nLPPpvz43jHMnrewwChXD9GGv6rJFrhW1NzcTPfujctsb2xqYnJzcwERFcdc5MxFzlzkzEXOXOTMRc5cZMwDPPSVgXRs3w6AP/9rIpffM2bxc8fvviGTps/htv+8UVR4Wg1ZALWyWM4yFiml5W6vdeYiZy5y5iJnLnLmImcucuYiU/Y8nHD1k3Sqb8dWvRr4/MAN+fLgzfn27S/Qq7ETx+7am1N+81TRIWo1YwHUipqampgyZfIy26dOmUL3xmWv3tQyc5EzFzlzkTMXOXORMxc5c5ExD/D869MBeGrcFCbPmsvwQ7fkukde5bS9N+ZvL73NK5Nm0q1j9pa2LoL6dnV069ie6XNcEW4Z5aiZ31PhBVBEHAD8CGgH/DKl9O2lnu8IXAvsCLwNHJVSeqXaca6MzfttsUw/7rhx45gxY8Yy/bu1zlzkzEXOXOTMRc5c5MxFzlxkzENLz0/MiqFejZ3ZsGcX+q27BoP6r91inyE7b8CQnTdg8OUP8+a0OUWEqTau0EUQIqId8L/AYGBL4OiI2HKp3U4EmlNKmwI/BL5T3ShX3v4HDOaeu+5k2rRpi7fdMPL3dO7cmY8N3LPAyKrPXOTMRc5c5MxFzlzkzEXOXGTMQ0vb9u4OwITJs7joz6M5+dp/tviaNH0Odz3zBidf+0+aZ84tOFq1VUWvArcz8FJK6eWU0lzgeuDQpfY5FLim8v0NwKBoo02vJ518Kh07dmTIEYdz76h7+NUvRnDJ8GGcefa5Nb1O//KYi5y5yJmLnLnImYucuciZi0yZ8/Djo7fh2F16s9smPdhl4yZO2bMv5+y7CXc+8wbjm2fz3MRpPDF2couvufMX8sbUOTwxdjLzFqSi/wltTLTp/1VT0S1w6wPjlng8HvjoivZJKc2PiClAT2DSkjtFxMnAyQC9+/RZVfG+q6amJm67cxTnnHU6nzrsEBobGznjrHO44MJhhcRTJHORMxc5c5EzFzlzkTMXOXORKXMenp04jYO3XZdejZ1YsDDxWvNsfnLvy9z4xIT3/mHpXURKxVXHEXEEsH9K6aTK42OBnVNKZyyxzzOVfcZXHo+p7PP2il53xx0HpL/94/FVG7wkSVJJ7X7pfUWH0GY8eeHHn0gpDSg6jvey9XY7plvu/lvRYazQJmt3rloei54BGg/0XuLxBsDSZf2ifcZHRHugO/BOdcKTJEmSakPbvImk+oq+B+gxYLOI2CgiOgBDgFuX2udW4LjK958G7k1FTltJkiRJWm0VOgNUuafndOBOsmWwr0opPRMRw4HHU0q3Ar8CfhMRL5HN/AwpLmJJkiRJq7OiW+BIKd0G3LbUtguX+H42cES145IkSZJqReDnoC5SdAucJEmSJFWNBZAkSZKk0rAAkiRJklQahd8DJEmSJKkKvAkIcAZIkiRJUolYAEmSJEkqDVvgJEmSpBIIe+AAZ4AkSZIklYgFkCRJkqTSsAVOkiRJKoGwAw5wBkiSJElSiVgASZIkSSoNW+AkSZKkErADLuMMkCRJkqTSsACSJEmSVBq2wEmSJEm1LlwFbhFngCRJkiSVhgWQJEmSpNKwBU6SJEkqBXvgwBkgSZIkSSViASRJkiSpNCyAJEmSJJWG9wBJkiRJNS5wGexFnAGSJEmSVBoWQJIkSZJKwxY4SZIkqQTsgMs4AyRJkiSpNCyAJEmSJJVGTbbAPfnkE5M618fYouMA1gQmFR1EG2EuMuYhZy5y5iJnLnLmImcucuYi11ZysWHRAawsV4HL1GQBlFJaq+gYACLi8ZTSgKLjaAvMRcY85MxFzlzkzEXOXOTMRc5c5MyFPihb4CRJkiSVRk3OAEmSJElqKVwHDnAGaFUbUXQAbYi5yJiHnLnImYucuciZi5y5yJmLnLnQBxIppaJjkCRJkrQKbbv9junOvz5SdBgrtF5jhyeqdU+XLXCSJElSGdgBB9gCJ0mSJKlELIAkSZIklYYtcFrlImI7YA5ASum5gsOR2hyPEUkrw3NFzlzow3AGaBWJiJ0jYveI+GjRsRQpIgYDfwK+CIyMiOMLDqlQjoucuch4jLTkuMiZi+WLiFK+d/FckTMXH1y04a9qKuVJZFWLiP2BW4GDgN9FxOkR0a3gsKoqMt2AM4DTUkpnACcBX4+IU4uNrhiOi5y58BhZHsdFzlzkIuKgiPhWRFwaET1TSguLjqmaPFfkzIVaiwVQK6ocmB2Bo4EzU0pfAw4HDgVOjYjOhQZYRSkzHXgcaIiI+pTSI8AQ4MsRcVyxEVaP4yJnLnIeIznHRc5ctFSZ/foJMBpoAm6NiN0ior7YyKrHc0XOXKi1WAC1osqBOQd4DtgmIrqllJ4CzgYOBE4oNMBivA4MAjoDpJQeB44FzoiIjYoMrFocFzlzsVweI46LxczFMj4C3JVS+r+U0qnAjcBQYAcoXTtc6c8VSzAXH0BE2/6qpjKdOKrp30BPYJOIaJ9Segb4EnBuRGxbbGjVlVL6KdAFuDIiuleu1jxElqOyfQqv4yJnLio8Rlq8iS39uIhY/Dag9LmoeAzoHBFbAKSUfgA8BFweEY1laIeLiHbguQLy48Nc6MOyAGpFSxyYtwPTgbOAj1Su4D0B3EENfwRVROwSEcdW/tth0faU0lFkY+1y4ISIOA3YE5hfUKhVVfZxsTxlzUVEbBURe0bE2pXHi8ZGKY+RiNggIjosehNb1nEBEBFdIZsBqvy3tLlYyutkx8G+EbEmQErpe8DTwClFBrYqRcQeEXEsQEppwaK/qWU8V0REv4jYtdL2uPh9axlzodYTlXOtPqCIOATYOKX0o8rjukV/zCPiMmANYDYwDjgP2D2l9EpB4a4yEfEJ4GLgn0BX4KsppReXyscJQC9gW2BY5YpmTYqIzYDuZPkgpbRgiedKMy4AImJToBF4OqU0e6nnSpOLyFYt+g7wMlAPnJxSeq1y5XJeZZ8yHSP7A8OA/0kpvbxUHkozLgAi4lBgX2B4SunNsv4dWSQi2i11ztye7O/LHcBfU0r/iYivAAtTSpcVFeeqUJkN7QL8g6zQvSKldGXluU6LzqFlOVdExOHA/wNeq3w9Dvw6pTR1iX1KkYvWsN0OO6a77/9H0WGs0NoN9U+klAZU43dZAH0IEbEfcBnwpZTS3UtsX3zyjoi9gW2AzYH/TSk9W0iwq1BE9AT+DzgvpfR0RFwF3A7cD0xPKc1cav+OlR73mhQRhwHfAl4CxpPdvHtNSmnGEvvU/LgAiIiDyf54vU12JfeSyhhZ8s1uzeciIvYCRgDHpJQejYibyf6t9yz9Zq+yf60fI4vOnY3ALSmlsyrbS3XuBIiIPYGfA2cs+XdkqX3KkovNU0ovVL5vV5n5iJRSqhRBp5CNmQTsDByWUvpPgSGvMhExFFhA9qb+nymlH65gv5o9V1RmfK4jKwL/FhGfAnYh++yf76aUpiy1f83morVYAOUsgD6giNgNuBk4pPKGpjvZiXkSMCelNH+p/dsvva1WVP7tfwKuAO4CngKeAaYC/00pXVD54xUppScX/UErLuJVp1IMXkdWDD5buTL1BeAWspP41KX2r+VxsRtwFXB0SumfEfFToFNK6YTK84uvclce13Iu+gPrppTui4h1gSeBR4E3gL+nlH4dETuSdUDV+jGyD3Al2apmLwB/AS5OKT1Qeb404wIgIs4F6lJK34uIXsBWZOfO0SmlyUvtW7O5qFws+QPwx5TSZyrbFhVBdSmlhZUWuCZgJ7Lj5r8FhrxKVcZFH7K/rScBE8neW3y1cm6dXYJzRT3ZUvC/r5wj64CPkS0N/3JK6cqI2BmYX+u5aC0WQDnvAfrg3gbmAetV3vT+EfgZcDXZSiRExE4RcVBl/wXLfZUaULkKcwXwVbIC6OqU0iHAr4A+kS1juicwobJ/LZ+g5gPdgHUBUkpXAWOBtchO2lR6mWt+XFR8O6X0z8r33wR6RLbEL5U3NDtV3vhADecipfRcSum+ysMTgZ+mlA4DHgEOjIi+wEDKcYy0Az5baVPpSjZDuhVk90RVxsXOJTpGlixobiBb5e104CcRUR8R29V6Lir3P51OttLd3Ii4Dhbf+9J+iYJ4fkrpxZStCFezxU/FLcDrKaVRZG1fXyC7yApZAVjz54pKl8APgMMj4mOVcfAQ2UXWgZEtCb87JchFqyr6007byCehWgB9QCml0WRvaH8I/IusBexgsh7l/SNifWAjsiu9NX9gppRuAPYBHiS/7+VesmKgS0rp8pTS6wWGWBWVYvC3wPGRLQhxCVnv/rPAfpXdNqQc4+IfwE2weBWjjmT/9obKtg2ALcj+uNd6LhZLKV2SUrq48v3VZPd3dEgp/bAkx8idKaWHK1f1J5PNAH0zIrautDrVA5tQjmME4F7g8xFxPfCLlNLRZBcLZgD7k7W91XQuKu3BJ5D9HT0f6LREETQfILKV746JiE4R1V4wtxCzgH4R8XngVOBSoHdEfIasm6DmzxUVD5JdWD02IgamlBaklP6P7J6fXmU5b6r1tS86gNVZSulflavXe6eUflHZfFVEHAl0Syn9ocDwqi6l1BwR9wJHRsRcoBPQF6j1K3VL+x0wjawgnJxSOgayhSIioj3ZdH5NvpFZUuVejkUtfwFMBt5JKb0VEccA25PdsDqtqBirbekWjUpP+9pk46VUUr7y2x0RMQI4OCKeSSnNi4jry3CMAKTsnrjzyWbRX6hse3nRRYOy/B1JKU2ofDs9Ik4BRkTEdSmlYyJiG2BT4A9pqYVUalVKaUJEjAO+AZyWUvpT5V6wl8pybACklGZHxG/J7vv6amTLoc8h66qYXmhwWq1ZAH1IKbsZdfENqZU3NGsBU1b4Q7Xt78BmwNfJZj6OTzW8WtHyLJoFiojfpXwlp8+S9a53StmnWJdK5Sru9IgYFxGXks2GHV+m4gfyK/iVNsBjgHOBo1JKEwsNrHj/As4Bvku2sldp3uBV3E426zMsIsZWtm0HfLu4kIqTUnq7UgR9NyJGk3WrDEwpvVlwaNX2C7JFQp6oPL4/leBzj5ZWubj6C7L3WqeQvbc4JqX0RrGRrZ7KMH26MiyAWkllSv54sun7I8o6JVtpabkiIq4mW/Rg6nv9TK1KLZf/Pp/sjW7pih9YfHzUk93AWg8MSim9WGxUhVpIdlPz4ZV22lJLKd0YEUcBGwCvFBxO1VUuEFwbEU8DnyZrFz0+pfRSsZEVJ6U0KSL+DQwG9i3jRYKU0jhg3KKZ4zIWP4uklOYC90XEA9nD8uZCrcMCqHW9TPaG5vmiAyla2a7sv4dRwAMlfzOTyG5uvgh4rOTFz6Kbe28rOo62YIk3d0cWHUvRUkpPUrnfp+wiogk4ENgv1ehS1yurhDOiK5SW+sgA6YOyAGollRPUX4uOQ21PSmnse+9VGtf4x1xLcjxoeSptT4eU5Z4fSdVlASSpanyzK2llWfxIra8UayiuBJfBliRJklQaFkCSJEmSSsMWOEmSJKnmBeFC2IAzQJJUuIjoGxEpIn691PZfV7b3LSSw9+n9xhsRf42ID31fWES8EhGvfNjXeY/f0SqxSpKKZwEkqRQqb8yX/FoQEZMi4t6I+J+i41sVVlRYSZJUZrbASSqbb1X+Ww/0Aw4D9o6IHVNK5xYX1nJ9Ffg28FrRgUiSVm+Bq8AtYgEkqVRSSsOWfBwRg4C7gbMj4oqU0itFxLU8KaWJwMSi45AkqZbYAiep1FJKo4DnyS6O7QQtW8ciYvOI+H1EvBkRCyNir0U/GxE9IuLSiHguImZFxJSIGBUR+y3vd0XEGhHxg4gYHxGzI+L5iDiXFZyL3+2emojYuRLXaxExJyImRsRdEXFk5flhwH8rux+3VPvf55Z6rf0j4rZKS+CciBgTEd+NiMYVxLVPRDwYETMi4p2I+GNEbPEuaV5pEdEhIk6vxDO2Es87EXFPRAx+j5/tHhE/qeRkdkQ8GxFnRiz/mmdEfDQiboiI1yNibkSMi4ifR0Sv1vi3SJLaJmeAJInFy+IsfZP7JsA/gBeA3wKdgakAEbEh8FegL/AgcAfQFTgYuCMiTkkp/WLxL4joCIwiK7L+VXm9RuAbwJ7vK9iIzwM/AxYAtwIvAmsDA4AvAn+oxNYInFX5fX9c4iWeWuK1LiRrC3wH+DPwJrANcD5wYETsmlKausT+nwZ+D8yt/HcisAfwd+Df7+ffsQI9gB8BD5PNzL0FrMf/b+/+Y6+q6ziOP9+ShotGAloNyllqi6g0WWEThWZFbWQ/JMXWFpVtWkmt2bDVYLNS2xpmZQaJtanDZjX5w2RLhyir/IFa4mqRWTCT5g/IWsPUd398PjePl3u/fL8Xiuv3PB/s7nDP+ZzPOefe7cv3xecXLARujIizM/MHPc47BPgF5ZnX1vcfqnW9Dvh0s3BELAFWA7spn+E24Bjgk8DCiJiTmX/ZD88jSRoyBiBJrRYRp1J+QU7gzq7DJwEXZeaXepz6I+BIYHFmrm3U9zJK+LgsItZl5o566AuU8PNTYFFmPlvLXwzcPYb7nQlcTgliczNzS9fxGQCZuaHOjLYUuLe7618tO58Sfn4JvDczdzaOfQy4qh7/fN03Cfg+8Gy99l2N8iuBz432OUbwBHBkZm7vutfJwCbgGxFxTWb+q+u8VwIPArMyc3c9ZznlOz03Iq7LzI11/7H1OR4CTsnM/46xioh3UILXt4AP7IfnkSQNGbvASWqViFhRX1+LiOspLTcBXJqZf+4qvoPnJk1o1vFmSqvNT5rhB6CGiOXAREoLRMcSSnD4Yif81PJ/Ai4bwyOcQ/nPqwu7w0+tb/uep/R1Xt2e3Qw/tZ4fUlqKmjPknUZpobm2GX6qFcCuMVy7p8zc3esZMnMXsAY4jNpVsYcLOuGnnvM4cGF9u6RR7hzKJBhLm+GnnnMLpUVoYUS8dOAHkSQNLVuAJLXN8rpNYCel+9qVmXl1j7L3NX+hbjixbifXsTbdDq/b10MZ+wMcDWzLzD/2KL+hcV97M6dufz7K8iM5Efg3sCgiFvU4fghweERMzczHgLfU/bd2F8zMXRFxL2PsztdLRLwBOB84mdKyM7GryPQepz1N6TbXbUPdHt/Y1/n+TomIXmHqCGACcCxjaJ2TpGHnLHCFAUhSq2TmWH78P9Jn/9S6fWd99TOpbifX7Y4+5fpdp5fOxAT7Y2rsqZR/B/YWviYBj7F/n6OniJgD3FLv62ZKa8zfKa1nx1FaoV7c49RHM/OZEe5pcmNf5/s7fy+3M2kvxyVJL0AGIEnqr3tShI5OV6+lmTma7mud8i/vc/wVY7inTle16ZTZ6/bFLuCgzJwyhvKwf56jny9TJpuYn5kbmgci4gJKAOplWkRM6BGCOvfU7J7X+fvk5gQPkqR2cAyQJI3dr+p27mgKZ+aTwFZgekS8tkeReQNce8QpoatOGJgwQl2H1S5no7G5bvfo5lYnKThulPWM5Gjg8e7w0++6DS8C3t5j/7y6vaexb0zfnySNFzHEf/6fDECSNEZ1AoDbgA9GxMd7lYmIN0bEEY1dV1F+5l4SEQc1yh3Fc5MRjMb3KONdvlJnhOu+7ozG2ycorViv7lPXyrpd3Wvtm4h4Se2S1nFDrfOsiJjdVXwFz+9mNqiHgCkR8aaue/kE8O69nHtRnW68c84USosSlM+/4zuUsU8r64xwz1PXIjIcSdI4ZRc4SRrMWZSxKldGxHmU9YJ2AjMo6+jMogy2/1st/03g/ZSZ4TZHxHpKYDgD2Ai8bzQXzcwHIuJc4Argnoi4gbIO0FTKOkBPAvNr2X9ExK+BuRFxDWU9o2eAdZn5m8y8OSKWARcBf4iIGymLp06iTPF9CnA7sKBR36co6//cFhHNdYBm1ec4eUyf4p4upQSd2yPix5TuarPrNa4HTu9z3l8pY4Puj4h1lFneTqdMonB5Zwrs+hy/q8F1DbAlIm6qn83BlLA4l7L+0H5Z3FWSNFwMQJI0gMzcHhEnAJ+lhJqPULqaPQI8AHwb+G2j/O665tAKSuhZSmnt+CrwM0YZgGpdqyPifspipfMowepRykKk3YuEfpTS0rMAWEyZ8nt7LUtmXhIkT1fBAAACa0lEQVQRmyitUCdRxtjsokyysAq4tuva10fEAsrECR+mLCS6kRL2lrGPASgzb4qIhZSWmzMoge0OSqh7Df0D0FPAqcDXgTOBaZR1gS6mfBfd17k6Iu6jrM80H3gX8E/gYUrQum5fnkOSNLwis98YX0mSJEnjwfEnzM5bN91xoG+jr8mHTrg7M7u7V/9POAZIkiRJUmsYgCRJkiS1hmOAJEmSpHEu6ku2AEmSJElqEQOQJEmSpNawC5wkSZLUBvaBA2wBkiRJktQiBiBJkiRJrWEXOEmSJKkFwj5wgC1AkiRJklrEACRJkiSpNewCJ0mSJLVA2AMOsAVIkiRJUosYgCRJkiS1hgFIkiRJUms4BkiSJElqAYcAFbYASZIkSWoNA5AkSZKk1rALnCRJktQG9oEDbAGSJEmS1CIGIEmSJEmtYRc4SZIkqQXCPnCALUCSJEmSWsQAJEmSJKk1DECSJEnSOBdAxPC+RvUMEQsi4vcRsTUilg36WRiAJEmSJA21iJgAfBd4DzATWBwRMwepywAkSZIkadi9FdiamQ9m5lPAWuC0QSpyFjhJkiRpnNu8+e71hx4c0w70fYxgYkTc1Xi/KjNXNd5PB7Y13m8H3jbIhQxAkiRJ0jiXmQsO9D3so14jhXKQiuwCJ0mSJGnYbQde1Xg/A3h4kIoMQJIkSZKG3Z3AMRFxVEQcApwJrBukIrvASZIkSRpqmfl0RHwGWA9MANZk5pZB6orMgbrOSZIkSdILjl3gJEmSJLWGAUiSJElSaxiAJEmSJLWGAUiSJElSaxiAJEmSJLWGAUiSJElSaxiAJEmSJLXGfwAwIfQo3RG/7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from matplotlib.pyplot import MultipleLocator\n",
    "from sklearn.metrics import recall_score,accuracy_score, f1_score,  precision_score\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",fontsize=15,\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label',fontsize=20)\n",
    "    plt.xlabel('Predicted label',fontsize=20)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Prediction Results Demonstration (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[1.0,0.0,0.0,0.0,...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[0.01498374220428...|[0.16915373391696...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[21.4101342917317...|[0.98871926164854...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4053128285999...|[0.98867078803394...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4051969134680...|[0.98866960135354...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4045719380929...|[0.98866327442131...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4040750048511...|[0.98865824240213...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4042112583223...|[0.98865961533316...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[21.4042112583223...|[0.98865961533316...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[3,4,5,7],[3.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "|(9,[4,5,7,8],[2.0...|    0|[5100.0,0.0,0.0,0...|[1.0,0.0,0.0,0.0,...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o3497.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 2928.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2928.0 (TID 370363) (yuedembp executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.ml.linalg.DenseVector)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:83)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.GeneratedMethodAccessor155.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.ml.linalg.DenseVector)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:83)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-2985708e9187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmlp_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdt_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0movr_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/BigData/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \"\"\"\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BigData/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BigData/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/BigData/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o3497.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 2928.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2928.0 (TID 370363) (yuedembp executor driver): net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.ml.linalg.DenseVector)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:83)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2202)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2201)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2201)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2440)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2382)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2371)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:868)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2202)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2223)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2242)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:472)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:425)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:47)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3696)\n\tat org.apache.spark.sql.Dataset.$anonfun$head$1(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3687)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:772)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3685)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2722)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2929)\n\tat org.apache.spark.sql.Dataset.getRows(Dataset.scala:301)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:338)\n\tat sun.reflect.GeneratedMethodAccessor155.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: net.razorvine.pickle.PickleException: expected zero arguments for construction of ClassDict (for pyspark.ml.linalg.DenseVector)\n\tat net.razorvine.pickle.objects.ClassDictConstructor.construct(ClassDictConstructor.java:23)\n\tat net.razorvine.pickle.Unpickler.load_reduce(Unpickler.java:773)\n\tat net.razorvine.pickle.Unpickler.dispatch(Unpickler.java:213)\n\tat net.razorvine.pickle.Unpickler.load(Unpickler.java:123)\n\tat net.razorvine.pickle.Unpickler.loads(Unpickler.java:136)\n\tat org.apache.spark.sql.execution.python.BatchEvalPythonExec.$anonfun$evaluate$6(BatchEvalPythonExec.scala:83)\n\tat scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:484)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage7.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:755)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$getByteArrayRdd$1(SparkPlan.scala:345)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2(RDD.scala:898)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsInternal$2$adapted(RDD.scala:898)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:373)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:337)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "rf_predictions.show()\n",
    "lr_predictions.show()\n",
    "mlp_predictions.show()\n",
    "dt_predictions.show()\n",
    "ovr_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Prediction Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine the new dataframe\n",
    "# Extract prediction of target variable \"DriverWellbeing\"\n",
    "driverWellbeing_va = VectorAssembler(inputCols=[\"prediction\"], outputCol=\"driverWellbeing_prediction\")\n",
    "driverWellbeing_adj_prediction = driverWellbeing_va.setHandleInvalid(\"skip\").transform(rf_predictions_driverWellbeing)\n",
    "\n",
    "# Extract prediction of target variable \"DriverRush\"\n",
    "driverRush_va = VectorAssembler(inputCols=[\"prediction\"], outputCol=\"driverRush_prediction\")\n",
    "driverRush_adj_prediction = driverRush_va.setHandleInvalid(\"skip\").transform(rf_predictions_driverRush)\n",
    "\n",
    "# Extract prediction of target variable \"Rain Intensity\"\n",
    "rainIntensity_va = VectorAssembler(inputCols=[\"prediction\"], outputCol=\"rainIntensity_prediction\")\n",
    "rainIntensity_adj_prediction = rainIntensity_va.setHandleInvalid(\"skip\").transform(rf_predictions_rainInensity)\n",
    "\n",
    "# Extract prediction of target variable \"Vehicle Speed\"\n",
    "vehicleSpeed_va = VectorAssembler(inputCols=[\"prediction\"], outputCol=\"vehicleSpeed_prediction\")\n",
    "vehicleSpeed_adj_prediction = vehicleSpeed_va.setHandleInvalid(\"skip\").transform(rf_predictions_vehicleSpeed)\n",
    "\n",
    "\n",
    "### Target variable selection\n",
    "# Driver Wellbeing\n",
    "driverWellbeing_pred = driverWellbeing_adj_prediction.select(\"time\",\"driverWellbeing_prediction\")\n",
    "# Driver Rush\n",
    "driverRush_pred = driverRush_adj_prediction.select(\"driverRush_prediction\")\n",
    "# Rain Intensity\n",
    "rainIntensity_pred = rainIntensity_adj_prediction.select(\"rainIntensity_prediction\")\n",
    "# Vehicle Speed\n",
    "vehicleSpeed_pred = vehicleSpeed_adj_prediction.select(\"vehicleSpeed_prediction\")\n",
    "\n",
    "#### Combine\n",
    "driverWellbeing_pred = driverWellbeing_pred.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "driverRush_pred = driverRush_pred.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "rainIntensity_pred = rainIntensity_pred.withColumn(\"id\", monotonically_increasing_id())\n",
    "\n",
    "vehicleSpeed_pred = vehicleSpeed_pred.withColumn(\"id\", monotonically_increasing_id())\n",
    "combined_predictions= driverWellbeing_pred.join(driverRush_pred,\"id\", \"outer\")\n",
    "combined_predictions= combined_predictions.join(rainIntensity_pred,\"id\", \"outer\")\n",
    "combined_predictions= combined_predictions.join(vehicleSpeed_pred, \"id\", \"outer\").drop(\"id\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform into integer type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "udf1 = F.udf(lambda x : int(x[0]),IntegerType())\n",
    "combined_predictions = combined_predictions.select('time',udf1('driverWellbeing_prediction').alias('driverWellbeing'),udf1('driverRush_prediction').alias('driverRush'),udf1('rainIntensity_prediction').alias('rainIntensity'),udf1('vehicleSpeed_prediction').alias('vehicleSpeed'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save prediction file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_predictions.toPandas().to_csv('../Data/Global_Output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
